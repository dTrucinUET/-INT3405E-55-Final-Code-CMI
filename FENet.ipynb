{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T10:39:15.569649Z",
     "iopub.status.busy": "2024-12-04T10:39:15.568995Z",
     "iopub.status.idle": "2024-12-04T10:39:56.809279Z",
     "shell.execute_reply": "2024-12-04T10:39:56.808345Z",
     "shell.execute_reply.started": "2024-12-04T10:39:15.569592Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "!pip -q install /kaggle/input/pytorchtabnet/pytorch_tabnet-4.1.0-py3-none-any.whl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T10:39:56.811445Z",
     "iopub.status.busy": "2024-12-04T10:39:56.811141Z",
     "iopub.status.idle": "2024-12-04T10:39:59.074299Z",
     "shell.execute_reply": "2024-12-04T10:39:59.073367Z",
     "shell.execute_reply.started": "2024-12-04T10:39:56.811417Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetRegressor, TabNetClassifier\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T10:39:59.075956Z",
     "iopub.status.busy": "2024-12-04T10:39:59.075471Z",
     "iopub.status.idle": "2024-12-04T10:40:12.898933Z",
     "shell.execute_reply": "2024-12-04T10:40:12.898252Z",
     "shell.execute_reply.started": "2024-12-04T10:39:59.075916Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from scipy.optimize import minimize\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from tqdm import tqdm\n",
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator, PercentFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense\n",
    "from keras.optimizers import Adam\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from colorama import Fore, Style\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.impute import KNNImputer\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T10:40:12.900492Z",
     "iopub.status.busy": "2024-12-04T10:40:12.899881Z",
     "iopub.status.idle": "2024-12-04T10:40:12.909336Z",
     "shell.execute_reply": "2024-12-04T10:40:12.908533Z",
     "shell.execute_reply.started": "2024-12-04T10:40:12.900462Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "seed_everything(2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T10:40:12.912763Z",
     "iopub.status.busy": "2024-12-04T10:40:12.911991Z",
     "iopub.status.idle": "2024-12-04T10:40:12.937197Z",
     "shell.execute_reply": "2024-12-04T10:40:12.936529Z",
     "shell.execute_reply.started": "2024-12-04T10:40:12.912723Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "target_labels = ['None', 'Mild', 'Moderate', 'Severe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T10:40:12.938565Z",
     "iopub.status.busy": "2024-12-04T10:40:12.938239Z",
     "iopub.status.idle": "2024-12-04T10:40:13.092329Z",
     "shell.execute_reply": "2024-12-04T10:40:13.091497Z",
     "shell.execute_reply.started": "2024-12-04T10:40:12.938524Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (20, 59)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>id</th><th>Basic_Demos-Enroll_Season</th><th>Basic_Demos-Age</th><th>Basic_Demos-Sex</th><th>CGAS-Season</th><th>CGAS-CGAS_Score</th><th>Physical-Season</th><th>Physical-BMI</th><th>Physical-Height</th><th>Physical-Weight</th><th>Physical-Waist_Circumference</th><th>Physical-Diastolic_BP</th><th>Physical-HeartRate</th><th>Physical-Systolic_BP</th><th>Fitness_Endurance-Season</th><th>Fitness_Endurance-Max_Stage</th><th>Fitness_Endurance-Time_Mins</th><th>Fitness_Endurance-Time_Sec</th><th>FGC-Season</th><th>FGC-FGC_CU</th><th>FGC-FGC_CU_Zone</th><th>FGC-FGC_GSND</th><th>FGC-FGC_GSND_Zone</th><th>FGC-FGC_GSD</th><th>FGC-FGC_GSD_Zone</th><th>FGC-FGC_PU</th><th>FGC-FGC_PU_Zone</th><th>FGC-FGC_SRL</th><th>FGC-FGC_SRL_Zone</th><th>FGC-FGC_SRR</th><th>FGC-FGC_SRR_Zone</th><th>FGC-FGC_TL</th><th>FGC-FGC_TL_Zone</th><th>BIA-Season</th><th>BIA-BIA_Activity_Level_num</th><th>BIA-BIA_BMC</th><th>BIA-BIA_BMI</th><th>BIA-BIA_BMR</th><th>BIA-BIA_DEE</th><th>BIA-BIA_ECW</th><th>BIA-BIA_FFM</th><th>BIA-BIA_FFMI</th><th>BIA-BIA_FMI</th><th>BIA-BIA_Fat</th><th>BIA-BIA_Frame_num</th><th>BIA-BIA_ICW</th><th>BIA-BIA_LDM</th><th>BIA-BIA_LST</th><th>BIA-BIA_SMM</th><th>BIA-BIA_TBW</th><th>PAQ_A-Season</th><th>PAQ_A-PAQ_A_Total</th><th>PAQ_C-Season</th><th>PAQ_C-PAQ_C_Total</th><th>SDS-Season</th><th>SDS-SDS_Total_Raw</th><th>SDS-SDS_Total_T</th><th>PreInt_EduHx-Season</th><th>PreInt_EduHx-computerinternet_hoursday</th></tr><tr><td>str</td><td>enum</td><td>i64</td><td>i64</td><td>enum</td><td>i64</td><td>enum</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>enum</td><td>i64</td><td>i64</td><td>i64</td><td>enum</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>f64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>i64</td><td>f64</td><td>i64</td><td>f64</td><td>i64</td><td>enum</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>enum</td><td>f64</td><td>enum</td><td>f64</td><td>enum</td><td>i64</td><td>i64</td><td>enum</td><td>i64</td></tr></thead><tbody><tr><td>&quot;00008ff9&quot;</td><td>&quot;Fall&quot;</td><td>5</td><td>0</td><td>&quot;Winter&quot;</td><td>51</td><td>&quot;Fall&quot;</td><td>16.877316</td><td>46.0</td><td>50.8</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;Fall&quot;</td><td>0</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0</td><td>0</td><td>7.0</td><td>0</td><td>6.0</td><td>0</td><td>6.0</td><td>1</td><td>&quot;Fall&quot;</td><td>2</td><td>2.66855</td><td>16.8792</td><td>932.498</td><td>1492.0</td><td>8.25598</td><td>41.5862</td><td>13.8177</td><td>3.06143</td><td>9.21377</td><td>1</td><td>24.4349</td><td>8.89536</td><td>38.9177</td><td>19.5413</td><td>32.6909</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;Fall&quot;</td><td>3</td></tr><tr><td>&quot;000fd460&quot;</td><td>&quot;Summer&quot;</td><td>9</td><td>0</td><td>null</td><td>null</td><td>&quot;Fall&quot;</td><td>14.03559</td><td>48.0</td><td>46.0</td><td>22.0</td><td>75</td><td>70</td><td>122</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;Fall&quot;</td><td>3</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>5</td><td>0</td><td>11.0</td><td>1</td><td>11.0</td><td>1</td><td>3.0</td><td>0</td><td>&quot;Winter&quot;</td><td>2</td><td>2.57949</td><td>14.0371</td><td>936.656</td><td>1498.65</td><td>6.01993</td><td>42.0291</td><td>12.8254</td><td>1.21172</td><td>3.97085</td><td>1</td><td>21.0352</td><td>14.974</td><td>39.4497</td><td>15.4107</td><td>27.0552</td><td>null</td><td>null</td><td>&quot;Fall&quot;</td><td>2.34</td><td>&quot;Fall&quot;</td><td>46</td><td>64</td><td>&quot;Summer&quot;</td><td>0</td></tr><tr><td>&quot;00105258&quot;</td><td>&quot;Summer&quot;</td><td>10</td><td>1</td><td>&quot;Fall&quot;</td><td>71</td><td>&quot;Fall&quot;</td><td>16.648696</td><td>56.5</td><td>75.6</td><td>null</td><td>65</td><td>94</td><td>117</td><td>&quot;Fall&quot;</td><td>5</td><td>7</td><td>33</td><td>&quot;Fall&quot;</td><td>20</td><td>1</td><td>10.2</td><td>1</td><td>14.7</td><td>2</td><td>7</td><td>1</td><td>10.0</td><td>1</td><td>10.0</td><td>1</td><td>5.0</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;Summer&quot;</td><td>2.17</td><td>&quot;Fall&quot;</td><td>38</td><td>54</td><td>&quot;Summer&quot;</td><td>2</td></tr><tr><td>&quot;00115b9f&quot;</td><td>&quot;Winter&quot;</td><td>9</td><td>0</td><td>&quot;Fall&quot;</td><td>71</td><td>&quot;Summer&quot;</td><td>18.292347</td><td>56.0</td><td>81.6</td><td>null</td><td>60</td><td>97</td><td>117</td><td>&quot;Summer&quot;</td><td>6</td><td>9</td><td>37</td><td>&quot;Summer&quot;</td><td>18</td><td>1</td><td>null</td><td>null</td><td>null</td><td>null</td><td>5</td><td>0</td><td>7.0</td><td>0</td><td>7.0</td><td>0</td><td>7.0</td><td>1</td><td>&quot;Summer&quot;</td><td>3</td><td>3.84191</td><td>18.2943</td><td>1131.43</td><td>1923.44</td><td>15.5925</td><td>62.7757</td><td>14.074</td><td>4.22033</td><td>18.8243</td><td>2</td><td>30.4041</td><td>16.779</td><td>58.9338</td><td>26.4798</td><td>45.9966</td><td>null</td><td>null</td><td>&quot;Winter&quot;</td><td>2.451</td><td>&quot;Summer&quot;</td><td>31</td><td>45</td><td>&quot;Winter&quot;</td><td>0</td></tr><tr><td>&quot;0016bb22&quot;</td><td>&quot;Spring&quot;</td><td>18</td><td>1</td><td>&quot;Summer&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;Summer&quot;</td><td>1.04</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>&quot;00c0cd71&quot;</td><td>&quot;Winter&quot;</td><td>7</td><td>0</td><td>&quot;Summer&quot;</td><td>51</td><td>&quot;Spring&quot;</td><td>29.315775</td><td>54.0</td><td>121.6</td><td>null</td><td>80</td><td>75</td><td>99</td><td>&quot;Spring&quot;</td><td>4</td><td>5</td><td>32</td><td>&quot;Spring&quot;</td><td>6</td><td>1</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0</td><td>0</td><td>12.0</td><td>1</td><td>15.0</td><td>1</td><td>12.0</td><td>1</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;Spring&quot;</td><td>35</td><td>50</td><td>&quot;Winter&quot;</td><td>2</td></tr><tr><td>&quot;00d56d4b&quot;</td><td>&quot;Spring&quot;</td><td>5</td><td>1</td><td>&quot;Summer&quot;</td><td>80</td><td>&quot;Spring&quot;</td><td>17.284504</td><td>44.0</td><td>47.6</td><td>null</td><td>61</td><td>76</td><td>109</td><td>&quot;Spring&quot;</td><td>null</td><td>null</td><td>null</td><td>&quot;Spring&quot;</td><td>0</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0</td><td>0</td><td>10.5</td><td>1</td><td>10.0</td><td>1</td><td>7.0</td><td>1</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;Spring&quot;</td><td>37</td><td>53</td><td>&quot;Spring&quot;</td><td>0</td></tr><tr><td>&quot;00d9913d&quot;</td><td>&quot;Fall&quot;</td><td>10</td><td>1</td><td>null</td><td>null</td><td>&quot;Fall&quot;</td><td>19.893157</td><td>55.0</td><td>85.6</td><td>30.0</td><td>null</td><td>81</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;Fall&quot;</td><td>5</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0</td><td>0</td><td>0.0</td><td>0</td><td>0.0</td><td>0</td><td>9.0</td><td>1</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;Fall&quot;</td><td>1</td></tr><tr><td>&quot;00e6167c&quot;</td><td>&quot;Winter&quot;</td><td>6</td><td>0</td><td>&quot;Spring&quot;</td><td>60</td><td>&quot;Winter&quot;</td><td>30.094649</td><td>37.5</td><td>60.2</td><td>24.0</td><td>61</td><td>91</td><td>95</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;Winter&quot;</td><td>6</td><td>1</td><td>null</td><td>null</td><td>null</td><td>null</td><td>0</td><td>0</td><td>4.0</td><td>0</td><td>4.0</td><td>0</td><td>7.0</td><td>1</td><td>&quot;Winter&quot;</td><td>2</td><td>2.75035</td><td>17.2738</td><td>1003.07</td><td>1504.61</td><td>15.1456</td><td>49.1034</td><td>14.0898</td><td>3.18407</td><td>11.0966</td><td>1</td><td>23.6182</td><td>10.3396</td><td>46.3531</td><td>19.8886</td><td>38.7638</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;Winter&quot;</td><td>39</td><td>55</td><td>&quot;Winter&quot;</td><td>3</td></tr><tr><td>&quot;00ebc35d&quot;</td><td>&quot;Winter&quot;</td><td>10</td><td>0</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;Spring&quot;</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>null</td><td>&quot;Winter&quot;</td><td>2</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (20, 59)\n",
       "┌──────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ id       ┆ Basic_Dem ┆ Basic_Dem ┆ Basic_Dem ┆ … ┆ SDS-SDS_T ┆ SDS-SDS_T ┆ PreInt_Ed ┆ PreInt_Ed │\n",
       "│ ---      ┆ os-Enroll ┆ os-Age    ┆ os-Sex    ┆   ┆ otal_Raw  ┆ otal_T    ┆ uHx-Seaso ┆ uHx-compu │\n",
       "│ str      ┆ _Season   ┆ ---       ┆ ---       ┆   ┆ ---       ┆ ---       ┆ n         ┆ terintern │\n",
       "│          ┆ ---       ┆ i64       ┆ i64       ┆   ┆ i64       ┆ i64       ┆ ---       ┆ et_…      │\n",
       "│          ┆ enum      ┆           ┆           ┆   ┆           ┆           ┆ enum      ┆ ---       │\n",
       "│          ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆ i64       │\n",
       "╞══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 00008ff9 ┆ Fall      ┆ 5         ┆ 0         ┆ … ┆ null      ┆ null      ┆ Fall      ┆ 3         │\n",
       "│ 000fd460 ┆ Summer    ┆ 9         ┆ 0         ┆ … ┆ 46        ┆ 64        ┆ Summer    ┆ 0         │\n",
       "│ 00105258 ┆ Summer    ┆ 10        ┆ 1         ┆ … ┆ 38        ┆ 54        ┆ Summer    ┆ 2         │\n",
       "│ 00115b9f ┆ Winter    ┆ 9         ┆ 0         ┆ … ┆ 31        ┆ 45        ┆ Winter    ┆ 0         │\n",
       "│ 0016bb22 ┆ Spring    ┆ 18        ┆ 1         ┆ … ┆ null      ┆ null      ┆ null      ┆ null      │\n",
       "│ …        ┆ …         ┆ …         ┆ …         ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ 00c0cd71 ┆ Winter    ┆ 7         ┆ 0         ┆ … ┆ 35        ┆ 50        ┆ Winter    ┆ 2         │\n",
       "│ 00d56d4b ┆ Spring    ┆ 5         ┆ 1         ┆ … ┆ 37        ┆ 53        ┆ Spring    ┆ 0         │\n",
       "│ 00d9913d ┆ Fall      ┆ 10        ┆ 1         ┆ … ┆ null      ┆ null      ┆ Fall      ┆ 1         │\n",
       "│ 00e6167c ┆ Winter    ┆ 6         ┆ 0         ┆ … ┆ 39        ┆ 55        ┆ Winter    ┆ 3         │\n",
       "│ 00ebc35d ┆ Winter    ┆ 10        ┆ 0         ┆ … ┆ null      ┆ null      ┆ Winter    ┆ 2         │\n",
       "└──────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season_dtype = pl.Enum(['Spring', 'Summer', 'Fall', 'Winter'])\n",
    "\n",
    "train = (\n",
    "    pl.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv')\n",
    "    .with_columns(pl.col('^.*Season$').cast(season_dtype))\n",
    ")\n",
    "\n",
    "test = (\n",
    "    pl.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv')\n",
    "    .with_columns(pl.col('^.*Season$').cast(season_dtype))\n",
    ")\n",
    "\n",
    "train\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T10:40:17.549831Z",
     "iopub.status.busy": "2024-12-04T10:40:17.549593Z",
     "iopub.status.idle": "2024-12-04T10:40:17.565982Z",
     "shell.execute_reply": "2024-12-04T10:40:17.565243Z",
     "shell.execute_reply.started": "2024-12-04T10:40:17.549807Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def process_file(filename, dirname):\n",
    "    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "    df.drop('step', axis=1, inplace=True)\n",
    "    return df.describe().values.reshape(-1), filename.split('=')[1]\n",
    "\n",
    "def load_time_series(dirname) -> pd.DataFrame:\n",
    "    ids = os.listdir(dirname)\n",
    "    \n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    \n",
    "    stats, indexes = zip(*results)\n",
    "    \n",
    "    df = pd.DataFrame(stats, columns=[f\"stat_{i}\" for i in range(len(stats[0]))])\n",
    "    df['id'] = indexes\n",
    "    return df\n",
    "\n",
    "\n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, encoding_dim*3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(encoding_dim*3, encoding_dim*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(encoding_dim*2, encoding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, input_dim*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim*2, input_dim*3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(input_dim*3, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "def perform_autoencoder(df, encoding_dim=50, epochs=50, batch_size=32):\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(df)\n",
    "    \n",
    "    data_tensor = torch.FloatTensor(df_scaled)\n",
    "    \n",
    "    input_dim = data_tensor.shape[1]\n",
    "    autoencoder = AutoEncoder(input_dim, encoding_dim)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(autoencoder.parameters())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, len(data_tensor), batch_size):\n",
    "            batch = data_tensor[i : i + batch_size]\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed = autoencoder(batch)\n",
    "            loss = criterion(reconstructed, batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}]')\n",
    "                 \n",
    "    with torch.no_grad():\n",
    "        encoded_data = autoencoder.encoder(data_tensor).numpy()\n",
    "        \n",
    "    df_encoded = pd.DataFrame(encoded_data, columns=[f'Enc_{i + 1}' for i in range(encoded_data.shape[1])])\n",
    "    \n",
    "    return df_encoded\n",
    "\n",
    "def feature_engineering(df):\n",
    "    season_cols = [col for col in df.columns if 'Season' in col]\n",
    "    df = df.drop(season_cols, axis=1) \n",
    "    df['BMI_Age'] = df['Physical-BMI'] * df['Basic_Demos-Age']\n",
    "    df['Internet_Hours_Age'] = df['PreInt_EduHx-computerinternet_hoursday'] * df['Basic_Demos-Age']\n",
    "    df['BMI_Internet_Hours'] = df['Physical-BMI'] * df['PreInt_EduHx-computerinternet_hoursday']\n",
    "    df['BFP_BMI'] = df['BIA-BIA_Fat'] / df['BIA-BIA_BMI']\n",
    "    df['FFMI_BFP'] = df['BIA-BIA_FFMI'] / df['BIA-BIA_Fat']\n",
    "    df['FMI_BFP'] = df['BIA-BIA_FMI'] / df['BIA-BIA_Fat']\n",
    "    df['LST_TBW'] = df['BIA-BIA_LST'] / df['BIA-BIA_TBW']\n",
    "    df['BFP_BMR'] = df['BIA-BIA_Fat'] * df['BIA-BIA_BMR']\n",
    "    df['BFP_DEE'] = df['BIA-BIA_Fat'] * df['BIA-BIA_DEE']\n",
    "    df['BMR_Weight'] = df['BIA-BIA_BMR'] / df['Physical-Weight']\n",
    "    df['DEE_Weight'] = df['BIA-BIA_DEE'] / df['Physical-Weight']\n",
    "    df['SMM_Height'] = df['BIA-BIA_SMM'] / df['Physical-Height']\n",
    "    df['Muscle_to_Fat'] = df['BIA-BIA_SMM'] / df['BIA-BIA_FMI']\n",
    "    df['Hydration_Status'] = df['BIA-BIA_TBW'] / df['Physical-Weight']\n",
    "    df['ICW_TBW'] = df['BIA-BIA_ICW'] / df['BIA-BIA_TBW']\n",
    "    df['BMI_PHR'] = df['Physical-BMI'] * df['Physical-HeartRate']\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T10:40:17.567161Z",
     "iopub.status.busy": "2024-12-04T10:40:17.566926Z",
     "iopub.status.idle": "2024-12-04T10:41:31.298174Z",
     "shell.execute_reply": "2024-12-04T10:41:31.297268Z",
     "shell.execute_reply.started": "2024-12-04T10:40:17.567137Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [01:13<00:00, 13.56it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00,  9.16it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\")\n",
    "test_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T10:41:31.299465Z",
     "iopub.status.busy": "2024-12-04T10:41:31.299172Z",
     "iopub.status.idle": "2024-12-04T10:41:49.527929Z",
     "shell.execute_reply": "2024-12-04T10:41:49.526907Z",
     "shell.execute_reply.started": "2024-12-04T10:41:31.299438Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Loss: 1.6710]\n",
      "Epoch [20/100], Loss: 1.5469]\n",
      "Epoch [30/100], Loss: 1.5154]\n",
      "Epoch [40/100], Loss: 1.4932]\n",
      "Epoch [50/100], Loss: 1.4964]\n",
      "Epoch [60/100], Loss: 1.4920]\n",
      "Epoch [70/100], Loss: 1.4309]\n",
      "Epoch [80/100], Loss: 1.4185]\n",
      "Epoch [90/100], Loss: 1.3667]\n",
      "Epoch [100/100], Loss: 1.3620]\n",
      "Epoch [10/100], Loss: 1.0070]\n",
      "Epoch [20/100], Loss: 0.5783]\n",
      "Epoch [30/100], Loss: 0.4271]\n",
      "Epoch [40/100], Loss: 0.4271]\n",
      "Epoch [50/100], Loss: 0.4271]\n",
      "Epoch [60/100], Loss: 0.4271]\n",
      "Epoch [70/100], Loss: 0.4271]\n",
      "Epoch [80/100], Loss: 0.4271]\n",
      "Epoch [90/100], Loss: 0.4271]\n",
      "Epoch [100/100], Loss: 0.4271]\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv')\n",
    "sample = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/sample_submission.csv')\n",
    "\n",
    "df_train = train_ts.drop('id', axis=1)\n",
    "df_test = test_ts.drop('id', axis=1)\n",
    "\n",
    "train_ts_encoded = perform_autoencoder(df_train, encoding_dim=60, epochs=100, batch_size=32)\n",
    "test_ts_encoded = perform_autoencoder(df_test, encoding_dim=60, epochs=100, batch_size=32)\n",
    "\n",
    "time_series_cols = train_ts_encoded.columns.tolist()\n",
    "train_ts_encoded[\"id\"]=train_ts[\"id\"]\n",
    "test_ts_encoded['id']=test_ts[\"id\"]\n",
    "\n",
    "train = pd.merge(train, train_ts_encoded, how=\"left\", on='id')\n",
    "test = pd.merge(test, test_ts_encoded, how=\"left\", on='id')\n",
    "\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "numeric_cols = train.select_dtypes(include=['float64', 'int64']).columns\n",
    "imputed_data = imputer.fit_transform(train[numeric_cols])\n",
    "train_imputed = pd.DataFrame(imputed_data, columns=numeric_cols)\n",
    "train_imputed['sii'] = train_imputed['sii'].round().astype(int)\n",
    "for col in train.columns:\n",
    "    if col not in numeric_cols:\n",
    "        train_imputed[col] = train[col]\n",
    "        \n",
    "train = train_imputed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T10:41:49.530006Z",
     "iopub.status.busy": "2024-12-04T10:41:49.529263Z",
     "iopub.status.idle": "2024-12-04T10:41:49.538440Z",
     "shell.execute_reply": "2024-12-04T10:41:49.537484Z",
     "shell.execute_reply.started": "2024-12-04T10:41:49.529953Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "featuresCols = ['Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "                'CGAS-CGAS_Score', 'Physical-BMI',\n",
    "                'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "                'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "                'Fitness_Endurance-Max_Stage',\n",
    "                'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "                'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "                'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "                'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "                'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone',\n",
    "                'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "                'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "                'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "                'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "                'BIA-BIA_TBW', 'PAQ_A-PAQ_A_Total',\n",
    "                'PAQ_C-PAQ_C_Total', 'SDS-SDS_Total_Raw',\n",
    "                'SDS-SDS_Total_T',\n",
    "                'PreInt_EduHx-computerinternet_hoursday', 'BMI_Age','Internet_Hours_Age','BMI_Internet_Hours',\n",
    "                'BFP_BMI', 'FFMI_BFP', 'FMI_BFP', 'LST_TBW', 'BFP_BMR', 'BFP_DEE', 'BMR_Weight', 'DEE_Weight',\n",
    "                'SMM_Height', 'Muscle_to_Fat']\n",
    "train = train[[c for c in featuresCols if c in train.columns] + ['sii']]\n",
    "test = test[[c for c in featuresCols if c in train.columns]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T10:41:49.540174Z",
     "iopub.status.busy": "2024-12-04T10:41:49.539778Z",
     "iopub.status.idle": "2024-12-04T10:41:49.563342Z",
     "shell.execute_reply": "2024-12-04T10:41:49.562547Z",
     "shell.execute_reply.started": "2024-12-04T10:41:49.540125Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "select_cols = [c for c in train.columns if (not train[c].isnull().values.any()) and (train[c].dtype in ['float64', 'int64', 'float32', 'int32'])]\n",
    "X_df_train = train[select_cols].drop(columns=['sii'])\n",
    "y_df_train = train['sii']\n",
    "X_train = X_df_train.to_numpy()\n",
    "y_train = y_df_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T10:41:49.564421Z",
     "iopub.status.busy": "2024-12-04T10:41:49.564176Z",
     "iopub.status.idle": "2024-12-04T10:41:49.575111Z",
     "shell.execute_reply": "2024-12-04T10:41:49.574313Z",
     "shell.execute_reply.started": "2024-12-04T10:41:49.564398Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3960, 48)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor = torch.tensor(X_train).float()\n",
    "y_tensor = torch.tensor(y_train).float()\n",
    "\n",
    "X_scales = torch.clamp(X_tensor.max(dim=0, keepdim=True).values, 1)\n",
    "\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T10:41:49.576454Z",
     "iopub.status.busy": "2024-12-04T10:41:49.576176Z",
     "iopub.status.idle": "2024-12-04T10:41:49.584178Z",
     "shell.execute_reply": "2024-12-04T10:41:49.583517Z",
     "shell.execute_reply.started": "2024-12-04T10:41:49.576430Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from pytorch_tabnet.tab_model import TabNetClassifier\n",
    "\n",
    "def create_tabnet(in_dim, out_dim):\n",
    "    TabNet_Params = {\n",
    "        'n_d': 64,              # Width of the decision prediction layer\n",
    "        'n_a': 64,              # Width of the attention embedding for each step\n",
    "        'n_steps': 5,           # Number of steps in the architecture\n",
    "        'gamma': 1.5,           # Coefficient for feature selection regularization\n",
    "        'n_independent': 2,     # Number of independent GLU layer in each GLU block\n",
    "        'n_shared': 2,          # Number of shared GLU layer in each GLU block\n",
    "        'mask_type': 'entmax',\n",
    "    }\n",
    "    tabnetreg = TabNetClassifier(**TabNet_Params)\n",
    "    tabnetreg.fit(np.ones((out_dim, in_dim)), np.arange(out_dim), max_epochs=1)\n",
    "    return tabnetreg.network.train().cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T10:41:49.585504Z",
     "iopub.status.busy": "2024-12-04T10:41:49.585259Z",
     "iopub.status.idle": "2024-12-04T10:41:49.612059Z",
     "shell.execute_reply": "2024-12-04T10:41:49.611254Z",
     "shell.execute_reply.started": "2024-12-04T10:41:49.585480Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import copy\n",
    "\n",
    "def entropy_loss(p_logit):\n",
    "    p = F.softmax(p_logit, dim=-1)\n",
    "    return -1 * torch.sum(p * F.log_softmax(p_logit, dim=-1)) / p_logit.size()[0]\n",
    "\n",
    "class FFN(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim, encoding_dim=None, act=F.gelu, norm=True):\n",
    "        super(FFN, self).__init__()\n",
    "        if encoding_dim is None: encoding_dim = input_dim * 4\n",
    "        self.fc1 = nn.Linear(input_dim, encoding_dim)\n",
    "        self.fc_interm = nn.Linear(encoding_dim, encoding_dim)\n",
    "        self.fc2 = nn.Linear(encoding_dim, output_dim)\n",
    "        if norm: self.norm = nn.LayerNorm(encoding_dim)\n",
    "        else: self.norm = nn.Identity()\n",
    "        self.act = act\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = x + self.act(self.fc_interm(self.norm(x)))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, num_layers, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.num_layers = num_layers\n",
    "\n",
    "        h = [hidden_dim] * (num_layers - 1)\n",
    "        self.layers = nn.ModuleList(nn.Linear(n, k) for n, k in zip([input_dim] + h, h + [output_dim]))\n",
    "        self.dropouts = nn.ModuleList(nn.Dropout(dropout) for _ in range(num_layers - 1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        for i, layer in enumerate(self.layers):\n",
    "            x = layer(x)\n",
    "            if i < self.num_layers - 1:\n",
    "                x = F.relu(x)\n",
    "                x = self.dropouts[i](x)\n",
    "        return x\n",
    "\n",
    "    def _reset_parameters(self):\n",
    "        \n",
    "        for proj in self.layers:\n",
    "            nn.init.xavier_uniform_(proj.weight, gain=1)\n",
    "            nn.init.constant_(proj.bias, 0)\n",
    "            \n",
    "        self.layers[-1].weight.data *= 0.01\n",
    "        self.layers[-1].bias.data = torch.ones(4) * -1.098\n",
    "        \n",
    "class FeatEng(nn.Module):\n",
    "    def __init__(self, op='mult'):\n",
    "        super(FeatEng, self).__init__()\n",
    "        self.op = op\n",
    "        self.params = nn.Parameter(torch.randn(3))\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.op == 'div':\n",
    "            x = (x[:, [0]] /  (x[:, [1]].abs() + 1e-2))\n",
    "        elif self.op == 'mult':\n",
    "            x = x[:, [0]] * x[:, [1]]\n",
    "        elif self.op == 'relu':\n",
    "            x = F.relu(x[:, [0]] * self.params[0] + x[:, [1]] * self.params[1] + self.params[2])\n",
    "        else:\n",
    "            raise NotImplementedError()\n",
    "            \n",
    "        return x\n",
    "\n",
    "class FeatGen(nn.Module):\n",
    "    def __init__(self, n_feats, k=2, op='mult'):\n",
    "        super(FeatGen, self).__init__()\n",
    "\n",
    "        self.dist_select = nn.ParameterList([\n",
    "            nn.Parameter(torch.randn(n_feats))\n",
    "            for _ in range(k)\n",
    "        ])\n",
    "        \n",
    "        self.fc_fe = FeatEng(op)\n",
    "        self.k = k\n",
    "\n",
    "        self.trigger = nn.Parameter(torch.randn(2))\n",
    "\n",
    "        self.op = op\n",
    "        \n",
    "    def forward(self, x, fix_choice=False, hard=True, tau=1.):\n",
    "        feats = []\n",
    "        for i in range(self.k):\n",
    "            if fix_choice:\n",
    "                curr_sel = torch.zeros_like(self.dist_select[i]).to(x.device)\n",
    "                curr_sel[torch.argmax(self.dist_select[i])] = 1.0\n",
    "            else:\n",
    "                if hard: curr_sel = F.gumbel_softmax(self.dist_select[i], tau=tau, hard=True)\n",
    "                else: curr_sel = F.softmax(self.dist_select[i])\n",
    "            curr_feat = (x * curr_sel).sum(dim=1, keepdim=True)\n",
    "            feats.append(curr_feat)\n",
    "        new_feat = self.fc_fe(torch.concatenate(feats, dim=1))\n",
    "\n",
    "        if fix_choice: trigger = (self.trigger >= self.trigger[1]).float()\n",
    "        elif hard: trigger = F.gumbel_softmax(self.trigger, tau=tau, hard=True)\n",
    "        else: trigger = F.softmax(self.trigger)\n",
    "        new_feat *= trigger[0]\n",
    "        \n",
    "        return new_feat\n",
    "\n",
    "class FENet(nn.Module):\n",
    "    def __init__(self, n_feats, max_new_feats=10, k=2):\n",
    "        super(FENet, self).__init__()\n",
    "\n",
    "        self.feat_generators = nn.ModuleList(\n",
    "            [FeatGen(n_feats, k, 'div')\n",
    "            for _ in range(max_new_feats // 2)]\n",
    "            + [FeatGen(n_feats, k, 'mult')\n",
    "            for _ in range(max_new_feats // 2)]\n",
    "        )\n",
    "        self.n_feats = n_feats\n",
    "        width_mult = 1.0\n",
    "        self.pool1 = nn.ModuleList([\n",
    "            MLP(n_feats + len(self.feat_generators), int(128 * width_mult), 4, 4, 0.0),\n",
    "            MLP(n_feats + len(self.feat_generators), int(256 * width_mult), 4, 2, 0.0),\n",
    "            MLP(n_feats + len(self.feat_generators), int(64  * width_mult), 4, 4, 0.0),\n",
    "            MLP(n_feats + len(self.feat_generators), int(128 * width_mult), 4, 2, 0.0),\n",
    "        ])\n",
    "\n",
    "        self.tabnet1 = create_tabnet(n_feats + len(self.feat_generators), 4)\n",
    "        \n",
    "        self.pool2 = nn.ModuleList([\n",
    "            MLP(len(self.feat_generators), int(128 * width_mult), 4, 4, 0.0),\n",
    "            MLP(len(self.feat_generators), int(256 * width_mult), 4, 2, 0.0),\n",
    "            MLP(len(self.feat_generators), int(64  * width_mult), 4, 4, 0.0),\n",
    "            MLP(len(self.feat_generators), int(128 * width_mult), 4, 2, 0.0),\n",
    "        ])\n",
    "\n",
    "        self.tabnet2 = create_tabnet(len(self.feat_generators), 4)\n",
    "\n",
    "        self._reset_all_clf_parameters()\n",
    "        self.tau = 10.\n",
    "        \n",
    "    def _reset_all_clf_parameters(self):\n",
    "        for i in range(len(self.pool1)):\n",
    "            self.pool1[i]._reset_parameters()\n",
    "        self.tabnet1 = create_tabnet(self.n_feats + len(self.feat_generators), 4)\n",
    "        for i in range(len(self.pool2)):\n",
    "            self.pool2[i]._reset_parameters()\n",
    "        self.tabnet2 = create_tabnet(len(self.feat_generators), 4)\n",
    "    \n",
    "        \n",
    "    def forward(self, x, fix_choice=False, hard=True, tau=1.):\n",
    "        new_feats = []\n",
    "        for i, feat_gen in enumerate(self.feat_generators):\n",
    "            new_feat = feat_gen(x, fix_choice, hard, tau)\n",
    "            new_feats.append(new_feat)\n",
    "        new_feats = torch.concatenate(new_feats, dim=1)\n",
    "        return new_feats\n",
    "\n",
    "    def calculate_entropy(self):\n",
    "        ent = 0.0\n",
    "        cnt = 0.0\n",
    "        for i, feat_gen in enumerate(self.feat_generators):\n",
    "            for j, dist in enumerate(feat_gen.dist_select):\n",
    "                ent += entropy_loss(dist)\n",
    "                cnt += 1\n",
    "        ent /= cnt\n",
    "        return ent\n",
    "        \n",
    "        \n",
    "    def forward_sl(self, x, y, fix_choice=False, hard=True):\n",
    "        new_feats = self.forward(x, fix_choice, hard, self.tau)\n",
    "        all_feats = torch.concatenate([x, new_feats], dim=1)\n",
    "        loss = 0.0\n",
    "        \n",
    "        for clf in self.pool1:\n",
    "            loss += F.cross_entropy(clf(all_feats), y.long())\n",
    "        logits, M_loss = self.tabnet1(all_feats)\n",
    "        loss += F.cross_entropy(logits, y.long()) + M_loss\n",
    "\n",
    "        for clf in self.pool2:\n",
    "            loss += F.cross_entropy(clf(new_feats), y.long())\n",
    "        logits, M_loss = self.tabnet2(new_feats)\n",
    "        loss += F.cross_entropy(logits, y.long()) + M_loss\n",
    "        \n",
    "        if not fix_choice:\n",
    "            loss += 0.1 * self.calculate_entropy()\n",
    "        return loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T12:33:35.196350Z",
     "iopub.status.busy": "2024-12-04T12:33:35.195518Z",
     "iopub.status.idle": "2024-12-04T12:33:35.206729Z",
     "shell.execute_reply": "2024-12-04T12:33:35.205785Z",
     "shell.execute_reply.started": "2024-12-04T12:33:35.196314Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def print_features(fe_model):\n",
    "    fe_pred = fe_model.cuda().forward((X_tensor / X_scales).cuda(), True, True)\n",
    "    \n",
    "    gt_df = train.copy()\n",
    "    for ci, c in enumerate(X_df_train.columns):\n",
    "        gt_df[c] /= X_scales.numpy()[:, ci]\n",
    "    \n",
    "    mses = []\n",
    "    for newfeat_idx in range(fe_pred.shape[1]):\n",
    "        fg = fe_model.feat_generators[newfeat_idx]\n",
    "        feat_id = fg.dist_select[0].argmax().item()\n",
    "        feat_jd = fg.dist_select[1].argmax().item()\n",
    "        feat_i = X_df_train.columns[feat_id]\n",
    "        feat_j = X_df_train.columns[feat_jd]\n",
    "        if fg.op == 'mult':\n",
    "            gt = (gt_df[feat_i] * gt_df[feat_j]).to_numpy()\n",
    "        if fg.op == 'div':\n",
    "            gt = (gt_df[feat_i] / (gt_df[feat_j].abs() + 1e-2)).to_numpy()\n",
    "\n",
    "        trigger = (fg.trigger[0] > fg.trigger[1]).bool().item()\n",
    "        if trigger:\n",
    "            yp = fe_pred[:, newfeat_idx].cpu().numpy()\n",
    "            mses += [np.mean((yp - gt)**2)]\n",
    "        \n",
    "        if fg.op == 'mult':\n",
    "            print(f'df[\"Feat_{newfeat_idx}\"] = df[\"{feat_i}\"] * df[\"{feat_j}\"]; trigger = {trigger}')\n",
    "        if fg.op == 'div':\n",
    "            print(f'df[\"Feat_{newfeat_idx}\"] = df[\"{feat_i}\"] / df[\"{feat_j}\"]; trigger = {trigger}')\n",
    "    \n",
    "    print(f'dbg mse: {max(mses):.4f}')\n",
    "    \n",
    "def initialize_features(feat_tuples, n_feats, max_new_feats=10):\n",
    "    \n",
    "    def initialize_feat_gen(feat_id, feat_jd, op):\n",
    "        fg = FeatGen(n_feats, 2, op)\n",
    "        fg.dist_select[0].data *= 0.1\n",
    "        fg.dist_select[0].data -= 0.5\n",
    "        fg.dist_select[0][feat_id].data += 1.0\n",
    "        \n",
    "        fg.dist_select[1].data *= 0.1\n",
    "        fg.dist_select[1].data -= 0.5\n",
    "        fg.dist_select[1][feat_jd].data += 1.0\n",
    "        fg.trigger.data = torch.tensor([.5, -.5])\n",
    "        return fg\n",
    "    \n",
    "    feat_generators = []\n",
    "    \n",
    "    for feat_i, feat_j, op in feat_tuples:\n",
    "        feat_id = X_df_train.columns.get_loc(feat_i)\n",
    "        feat_jd = X_df_train.columns.get_loc(feat_j)\n",
    "        fg = initialize_feat_gen(feat_id, feat_jd, op)\n",
    "        feat_generators += [fg]\n",
    "\n",
    "    while len(feat_generators) + 2 <= max_new_feats:\n",
    "        feat_generators += [FeatGen(n_feats, 2, 'mult'), FeatGen(n_feats, 2, 'div')]\n",
    "    feat_generators = nn.ModuleList(feat_generators)\n",
    "    fe_model = FENet(n_feats, max_new_feats)\n",
    "    fe_model.feat_generators = feat_generators\n",
    "    return fe_model\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T10:41:49.629529Z",
     "iopub.status.busy": "2024-12-04T10:41:49.628929Z",
     "iopub.status.idle": "2024-12-04T10:41:50.466239Z",
     "shell.execute_reply": "2024-12-04T10:41:50.465358Z",
     "shell.execute_reply.started": "2024-12-04T10:41:49.629497Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.0     |  0:00:00s\n",
      "epoch 0  | loss: 0.0     |  0:00:00s\n",
      "epoch 0  | loss: 0.0     |  0:00:00s\n",
      "epoch 0  | loss: 0.0     |  0:00:00s\n",
      "df[\"Feat_0\"] = df[\"Physical-BMI\"] * df[\"Basic_Demos-Age\"]; trigger = True\n",
      "df[\"Feat_1\"] = df[\"PreInt_EduHx-computerinternet_hoursday\"] * df[\"Basic_Demos-Age\"]; trigger = True\n",
      "df[\"Feat_2\"] = df[\"Physical-BMI\"] * df[\"PreInt_EduHx-computerinternet_hoursday\"]; trigger = True\n",
      "df[\"Feat_3\"] = df[\"BIA-BIA_Fat\"] / df[\"BIA-BIA_BMI\"]; trigger = True\n",
      "df[\"Feat_4\"] = df[\"BIA-BIA_FFMI\"] / df[\"BIA-BIA_Fat\"]; trigger = True\n",
      "df[\"Feat_5\"] = df[\"BIA-BIA_FMI\"] / df[\"BIA-BIA_Fat\"]; trigger = True\n",
      "df[\"Feat_6\"] = df[\"BIA-BIA_LST\"] / df[\"BIA-BIA_TBW\"]; trigger = True\n",
      "df[\"Feat_7\"] = df[\"BIA-BIA_Fat\"] * df[\"BIA-BIA_BMR\"]; trigger = True\n",
      "df[\"Feat_8\"] = df[\"BIA-BIA_Fat\"] * df[\"BIA-BIA_DEE\"]; trigger = True\n",
      "df[\"Feat_9\"] = df[\"BIA-BIA_BMR\"] / df[\"Physical-Weight\"]; trigger = True\n",
      "df[\"Feat_10\"] = df[\"BIA-BIA_DEE\"] / df[\"Physical-Weight\"]; trigger = True\n",
      "df[\"Feat_11\"] = df[\"BIA-BIA_SMM\"] / df[\"Physical-Height\"]; trigger = True\n",
      "df[\"Feat_12\"] = df[\"BIA-BIA_SMM\"] / df[\"BIA-BIA_FMI\"]; trigger = True\n",
      "df[\"Feat_13\"] = df[\"BIA-BIA_TBW\"] / df[\"Physical-Weight\"]; trigger = True\n",
      "df[\"Feat_14\"] = df[\"BIA-BIA_ICW\"] / df[\"BIA-BIA_TBW\"]; trigger = True\n",
      "df[\"Feat_15\"] = df[\"Physical-BMI\"] * df[\"Physical-HeartRate\"]; trigger = True\n",
      "df[\"Feat_16\"] = df[\"BIA-BIA_Fat\"] * df[\"FGC-FGC_SRL\"]; trigger = False\n",
      "df[\"Feat_17\"] = df[\"Physical-Systolic_BP\"] / df[\"BIA-BIA_BMI\"]; trigger = True\n",
      "df[\"Feat_18\"] = df[\"Physical-BMI\"] * df[\"FGC-FGC_SRL\"]; trigger = True\n",
      "df[\"Feat_19\"] = df[\"BIA-BIA_Frame_num\"] / df[\"FGC-FGC_CU\"]; trigger = False\n",
      "dbg mse: 0.0000\n"
     ]
    }
   ],
   "source": [
    "fe_model_init = initialize_features(\n",
    "    [\n",
    "        ('Physical-BMI', 'Basic_Demos-Age', 'mult'),\n",
    "        ('PreInt_EduHx-computerinternet_hoursday', 'Basic_Demos-Age', 'mult'),\n",
    "        ('Physical-BMI', 'PreInt_EduHx-computerinternet_hoursday', 'mult'),\n",
    "        ('BIA-BIA_Fat', 'BIA-BIA_BMI', 'div'),\n",
    "        ('BIA-BIA_FFMI', 'BIA-BIA_Fat', 'div'),\n",
    "        ('BIA-BIA_FMI', 'BIA-BIA_Fat', 'div'),\n",
    "        ('BIA-BIA_LST', 'BIA-BIA_TBW', 'div'),\n",
    "        ('BIA-BIA_Fat', 'BIA-BIA_BMR', 'mult'),\n",
    "        ('BIA-BIA_Fat', 'BIA-BIA_DEE', 'mult'),\n",
    "        ('BIA-BIA_BMR', 'Physical-Weight', 'div'),\n",
    "        ('BIA-BIA_DEE', 'Physical-Weight', 'div'),\n",
    "        ('BIA-BIA_SMM', 'Physical-Height', 'div'),\n",
    "        ('BIA-BIA_SMM', 'BIA-BIA_FMI', 'div'),\n",
    "        ('BIA-BIA_TBW', 'Physical-Weight', 'div'),\n",
    "        ('BIA-BIA_ICW', 'BIA-BIA_TBW', 'div'),\n",
    "        ('Physical-BMI', 'Physical-HeartRate', 'mult'),\n",
    "    ],\n",
    "    X_train.shape[1], 20\n",
    ")\n",
    "print_features(fe_model_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T10:41:50.467670Z",
     "iopub.status.busy": "2024-12-04T10:41:50.467348Z",
     "iopub.status.idle": "2024-12-04T10:41:50.473373Z",
     "shell.execute_reply": "2024-12-04T10:41:50.472449Z",
     "shell.execute_reply.started": "2024-12-04T10:41:50.467642Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X_np = (X_tensor / X_scales).cpu().numpy()\n",
    "y_np = (y_tensor).long().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T10:41:50.474845Z",
     "iopub.status.busy": "2024-12-04T10:41:50.474603Z",
     "iopub.status.idle": "2024-12-04T10:41:50.484080Z",
     "shell.execute_reply": "2024-12-04T10:41:50.483252Z",
     "shell.execute_reply.started": "2024-12-04T10:41:50.474820Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def linear_annealing(step, begin_val, end_val, total_steps):\n",
    "    return begin_val + (end_val - begin_val) * (step / total_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T10:41:50.485360Z",
     "iopub.status.busy": "2024-12-04T10:41:50.485079Z",
     "iopub.status.idle": "2024-12-04T10:41:50.500095Z",
     "shell.execute_reply": "2024-12-04T10:41:50.499352Z",
     "shell.execute_reply.started": "2024-12-04T10:41:50.485317Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1070.16K\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def get_model_size(model):\n",
    "    model_parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    model_size = sum([np.prod(p.size()) for p in model_parameters])\n",
    "    return \"{}K\".format(round(model_size / 1e+1) / 1e2)\n",
    "\n",
    "print(get_model_size(fe_model_init))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T12:32:17.072998Z",
     "iopub.status.busy": "2024-12-04T12:32:17.072758Z",
     "iopub.status.idle": "2024-12-04T12:32:17.084990Z",
     "shell.execute_reply": "2024-12-04T12:32:17.084075Z",
     "shell.execute_reply.started": "2024-12-04T12:32:17.072973Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k\n"
     ]
    }
   ],
   "source": [
    "print('k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T10:41:50.501409Z",
     "iopub.status.busy": "2024-12-04T10:41:50.501116Z",
     "iopub.status.idle": "2024-12-04T10:41:50.513867Z",
     "shell.execute_reply": "2024-12-04T10:41:50.513026Z",
     "shell.execute_reply.started": "2024-12-04T10:41:50.501379Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1068144"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum([p.numel() for n, p in fe_model_init.named_parameters() if \"feat_generators\" not in n and p.requires_grad])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T10:41:50.515313Z",
     "iopub.status.busy": "2024-12-04T10:41:50.515053Z",
     "iopub.status.idle": "2024-12-04T12:01:52.634082Z",
     "shell.execute_reply": "2024-12-04T12:01:52.633254Z",
     "shell.execute_reply.started": "2024-12-04T10:41:50.515289Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.0     |  0:00:00s\n",
      "epoch 0  | loss: 0.0     |  0:00:00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 10.4131, tau: 10.0000, ent: 0.0230, lr: 1.000e-03: 100%|██████████| 200/200 [02:49<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 0.0     |  0:00:00s\n",
      "epoch 0  | loss: 0.0     |  0:00:00s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 12.5922, tau: 1.9996, ent: 0.0221, lr: 1.000e-03:   0%|          | 0/5000 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 0, loss=12.4985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 11.7800, tau: 1.9616, ent: 0.0235, lr: 1.000e-03:   2%|▏         | 101/5000 [01:34<1:15:41,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 100, loss=11.7925\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 11.5742, tau: 1.9236, ent: 0.0152, lr: 1.000e-03:   4%|▍         | 201/5000 [03:07<1:13:08,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 200, loss=11.5939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 11.2333, tau: 1.8856, ent: 0.0096, lr: 1.000e-03:   6%|▌         | 301/5000 [04:41<1:11:55,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 300, loss=11.2468\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 11.1048, tau: 1.8476, ent: 0.0084, lr: 1.000e-03:   8%|▊         | 401/5000 [06:15<1:10:31,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 400, loss=11.0983\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 10.6449, tau: 1.8096, ent: 0.0070, lr: 1.000e-03:  10%|█         | 501/5000 [07:48<1:09:03,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 500, loss=10.6448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 10.4590, tau: 1.7716, ent: 0.0059, lr: 1.000e-03:  12%|█▏        | 601/5000 [09:22<1:06:28,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 600, loss=10.3871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 10.2920, tau: 1.7336, ent: 0.0045, lr: 1.000e-03:  14%|█▍        | 701/5000 [10:55<1:05:40,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 700, loss=10.2688\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 10.3438, tau: 1.6956, ent: 0.0045, lr: 1.000e-03:  16%|█▌        | 801/5000 [12:28<1:02:44,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 800, loss=10.3097\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 9.5437, tau: 1.6576, ent: 0.0034, lr: 1.000e-03:  18%|█▊        | 901/5000 [14:01<1:01:47,  1.11it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 900, loss=9.5352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 9.5930, tau: 1.6196, ent: 0.0035, lr: 5.000e-04:  20%|██        | 1001/5000 [15:34<1:01:50,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1000, loss=9.5488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 9.3192, tau: 1.5816, ent: 0.0036, lr: 5.000e-04:  22%|██▏       | 1101/5000 [17:06<1:01:17,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1100, loss=9.2772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 9.3712, tau: 1.5436, ent: 0.0049, lr: 5.000e-04:  24%|██▍       | 1201/5000 [18:39<59:37,  1.06it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1200, loss=9.3378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 9.4511, tau: 1.5056, ent: 0.0049, lr: 5.000e-04:  26%|██▌       | 1301/5000 [20:11<58:41,  1.05it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1300, loss=9.3466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 9.0421, tau: 1.4676, ent: 0.0042, lr: 5.000e-04:  28%|██▊       | 1401/5000 [21:43<55:04,  1.09it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1400, loss=9.0086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.9150, tau: 1.4296, ent: 0.0050, lr: 5.000e-04:  30%|███       | 1501/5000 [23:16<53:20,  1.09it/s]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1500, loss=8.9126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.6218, tau: 1.3916, ent: 0.0052, lr: 5.000e-04:  32%|███▏      | 1601/5000 [24:50<57:17,  1.01s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1600, loss=8.5974\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.5532, tau: 1.3536, ent: 0.0052, lr: 5.000e-04:  34%|███▍      | 1701/5000 [26:24<53:27,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1700, loss=8.5357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.8086, tau: 1.3156, ent: 0.0043, lr: 5.000e-04:  36%|███▌      | 1801/5000 [27:57<48:41,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1800, loss=8.8004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.4957, tau: 1.2776, ent: 0.0038, lr: 5.000e-04:  38%|███▊      | 1901/5000 [29:29<46:10,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 1900, loss=8.4724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.6213, tau: 1.2396, ent: 0.0041, lr: 2.500e-04:  40%|████      | 2001/5000 [31:01<44:36,  1.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2000, loss=8.5921\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.6246, tau: 1.2016, ent: 0.0041, lr: 2.500e-04:  42%|████▏     | 2101/5000 [32:34<44:46,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2100, loss=8.5946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.5914, tau: 1.1636, ent: 0.0043, lr: 2.500e-04:  44%|████▍     | 2201/5000 [34:06<42:25,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2200, loss=8.5576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.5190, tau: 1.1256, ent: 0.0041, lr: 2.500e-04:  46%|████▌     | 2301/5000 [35:39<41:42,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2300, loss=8.5071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.4629, tau: 1.0876, ent: 0.0042, lr: 2.500e-04:  48%|████▊     | 2401/5000 [37:11<40:07,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2400, loss=8.4435\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.3282, tau: 1.0496, ent: 0.0035, lr: 2.500e-04:  50%|█████     | 2501/5000 [38:44<38:31,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2500, loss=8.3240\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.4163, tau: 1.0116, ent: 0.0036, lr: 2.500e-04:  52%|█████▏    | 2601/5000 [40:16<35:53,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2600, loss=8.4022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.2164, tau: 0.9736, ent: 0.0031, lr: 2.500e-04:  54%|█████▍    | 2701/5000 [41:48<34:38,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2700, loss=8.1961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.3494, tau: 0.9356, ent: 0.0039, lr: 2.500e-04:  56%|█████▌    | 2801/5000 [43:20<34:44,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2800, loss=8.3238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.1811, tau: 0.8976, ent: 0.0034, lr: 2.500e-04:  58%|█████▊    | 2901/5000 [44:54<31:51,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 2900, loss=8.1550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.4213, tau: 0.8596, ent: 0.0040, lr: 1.250e-04:  60%|██████    | 3001/5000 [46:26<31:31,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 3000, loss=8.4305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.2814, tau: 0.8216, ent: 0.0038, lr: 1.250e-04:  62%|██████▏   | 3101/5000 [47:58<28:34,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 3100, loss=8.2830\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.1175, tau: 0.7836, ent: 0.0038, lr: 1.250e-04:  64%|██████▍   | 3201/5000 [49:31<28:11,  1.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 3200, loss=8.1195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.1497, tau: 0.7456, ent: 0.0038, lr: 1.250e-04:  66%|██████▌   | 3301/5000 [51:03<26:20,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 3300, loss=8.1309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.2088, tau: 0.7076, ent: 0.0034, lr: 1.250e-04:  68%|██████▊   | 3401/5000 [52:35<25:00,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 3400, loss=8.1844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 7.9446, tau: 0.6696, ent: 0.0032, lr: 1.250e-04:  70%|███████   | 3501/5000 [54:07<23:27,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 3500, loss=7.9438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 7.9807, tau: 0.6316, ent: 0.0033, lr: 1.250e-04:  72%|███████▏  | 3601/5000 [55:39<21:02,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 3600, loss=7.9607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 7.9381, tau: 0.5936, ent: 0.0031, lr: 1.250e-04:  74%|███████▍  | 3701/5000 [57:12<19:38,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 3700, loss=7.9567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 7.9211, tau: 0.5556, ent: 0.0029, lr: 1.250e-04:  76%|███████▌  | 3801/5000 [58:44<18:02,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 3800, loss=7.9541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.0604, tau: 0.5176, ent: 0.0029, lr: 1.250e-04:  78%|███████▊  | 3901/5000 [1:00:17<16:54,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 3900, loss=8.0239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.0979, tau: 0.4796, ent: 0.0029, lr: 6.250e-05:  80%|████████  | 4001/5000 [1:01:50<15:04,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 4000, loss=8.1209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.0287, tau: 0.4416, ent: 0.0029, lr: 6.250e-05:  82%|████████▏ | 4101/5000 [1:03:22<13:33,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 4100, loss=8.0107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 7.9543, tau: 0.4036, ent: 0.0030, lr: 6.250e-05:  84%|████████▍ | 4201/5000 [1:04:55<12:22,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 4200, loss=7.9226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 7.8416, tau: 0.3656, ent: 0.0031, lr: 6.250e-05:  86%|████████▌ | 4301/5000 [1:06:27<10:39,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 4300, loss=7.8388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.0316, tau: 0.3276, ent: 0.0030, lr: 6.250e-05:  88%|████████▊ | 4401/5000 [1:07:59<09:12,  1.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 4400, loss=8.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 7.8889, tau: 0.2896, ent: 0.0030, lr: 6.250e-05:  90%|█████████ | 4501/5000 [1:09:32<07:36,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 4500, loss=7.7569\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 7.7963, tau: 0.2516, ent: 0.0029, lr: 6.250e-05:  92%|█████████▏| 4601/5000 [1:11:04<06:13,  1.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 4600, loss=7.7961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 7.8763, tau: 0.2136, ent: 0.0030, lr: 6.250e-05:  94%|█████████▍| 4701/5000 [1:12:36<04:32,  1.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 4700, loss=7.8682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.0707, tau: 0.1756, ent: 0.0029, lr: 6.250e-05:  96%|█████████▌| 4801/5000 [1:14:08<03:02,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 4800, loss=8.0957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.0026, tau: 0.1376, ent: 0.0030, lr: 6.250e-05:  98%|█████████▊| 4901/5000 [1:15:41<01:34,  1.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ep 4900, loss=8.0328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 7.9498, tau: 0.1004, ent: 0.0030, lr: 6.250e-05: 100%|██████████| 5000/5000 [1:17:12<00:00,  1.08it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import copy\n",
    "fe_model = copy.deepcopy(fe_model_init)\n",
    "\n",
    "param_dicts = [\n",
    "    {\n",
    "        \"params\": [p for n, p in fe_model.named_parameters() if \"feat_generators\" in n and p.requires_grad],\n",
    "        \"lr\": 1e-1,\n",
    "    },\n",
    "    {\n",
    "        \"params\": [p for n, p in fe_model.named_parameters() if \"feat_generators\" not in n and p.requires_grad],\n",
    "        \"lr\": 1e-3,\n",
    "    }\n",
    "]\n",
    "\n",
    "\n",
    "ema_loss = None\n",
    "\n",
    "X_scales = torch.clamp(X_tensor.max(dim=0, keepdim=True).values, 1)\n",
    "X_tensor_scaled = X_tensor / X_scales\n",
    "\n",
    "\n",
    "batch_size=500\n",
    "\n",
    "\n",
    "\n",
    "fe_model.train().cpu()\n",
    "fe_model._reset_all_clf_parameters()\n",
    "fe_model.train().cuda()\n",
    "\n",
    "optimizer = optim.Adam(param_dicts)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 200, gamma=0.5)\n",
    "epochs = 200\n",
    "fe_model.cuda().train()\n",
    "pbar = tqdm(range(epochs), delay=1.0, position=0, leave=True)\n",
    "for epoch in pbar:\n",
    "    for i in range(0, len(X_tensor), batch_size):\n",
    "        batch = X_tensor_scaled[i : i + batch_size].cuda()\n",
    "        labels = y_tensor[i : i + len(batch)].cuda()\n",
    "        optimizer.zero_grad()\n",
    "        loss = fe_model.forward_sl(batch, labels, fix_choice=False, hard=False)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # grad = torch.nn.utils.clip_grad_norm_(fe_model.parameters(), .1)\n",
    "\n",
    "        if ema_loss is None: ema_loss = loss.item()\n",
    "        ema_loss = 0.9 * ema_loss + 0.1 * loss.item()\n",
    "        if i % (batch_size * 10) == 0: \n",
    "            pbar.set_description_str(f'loss: {ema_loss:.4f}, tau: {fe_model.tau:.4f}, ent: {fe_model.calculate_entropy():.4f}, lr: {scheduler.get_last_lr()[-1]:.3e}')\n",
    "    pbar.set_description_str(f'loss: {ema_loss:.4f}, tau: {fe_model.tau:.4f}, ent: {fe_model.calculate_entropy():.4f}, lr: {scheduler.get_last_lr()[-1]:.3e}')\n",
    "\n",
    "fe_model.train().cpu()\n",
    "fe_model._reset_all_clf_parameters()\n",
    "fe_model.train().cuda()\n",
    "\n",
    "optimizer = optim.Adam(param_dicts, lr=1e-3)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1000, gamma=0.5)\n",
    "epochs = 5000\n",
    "pbar = tqdm(range(epochs), delay=1.0, position=0, leave=True)\n",
    "for epoch in pbar:\n",
    "    fe_model.tau = linear_annealing(epoch, 2., .1, epochs)\n",
    "    for i in range(0, len(X_tensor), batch_size):\n",
    "        batch = X_tensor_scaled[i : i + batch_size].cuda()\n",
    "        labels = y_tensor[i : i + batch_size].cuda()\n",
    "        optimizer.zero_grad()\n",
    "        loss = fe_model.forward_sl(batch, labels, fix_choice=False, hard=True)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # grad = torch.nn.utils.clip_grad_norm_(fe_model.parameters(), .1)\n",
    "\n",
    "        if ema_loss is None: ema_loss = loss.item()\n",
    "        ema_loss = 0.9 * ema_loss + 0.1 * loss.item()\n",
    "        if i % (batch_size * 10) == 0: \n",
    "            pbar.set_description_str(f'loss: {ema_loss:.4f}, tau: {fe_model.tau:.4f}, ent: {fe_model.calculate_entropy():.4f}, lr: {scheduler.get_last_lr()[-1]:.3e}')\n",
    "    pbar.set_description_str(f'loss: {ema_loss:.4f}, tau: {fe_model.tau:.4f}, ent: {fe_model.calculate_entropy():.4f}, lr: {scheduler.get_last_lr()[-1]:.3e}')\n",
    "    scheduler.step()\n",
    "    if epoch % 100 == 0: print(f'Ep {epoch}, loss={ema_loss:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T12:32:38.819201Z",
     "iopub.status.busy": "2024-12-04T12:32:38.818559Z",
     "iopub.status.idle": "2024-12-04T12:32:38.823170Z",
     "shell.execute_reply": "2024-12-04T12:32:38.822339Z",
     "shell.execute_reply.started": "2024-12-04T12:32:38.819152Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# fe_model.train().cpu()\n",
    "# fe_model._reset_all_clf_parameters()\n",
    "# fe_model.train().cuda()\n",
    "\n",
    "# optimizer = optim.Adam(fe_model.parameters(), lr=1e-3)\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 200, gamma=0.5)\n",
    "# epochs = 500\n",
    "# batch_size=500\n",
    "# pbar = tqdm(range(epochs), delay=1.0, position=0, leave=True)\n",
    "# for epoch in pbar:\n",
    "#     for i in range(0, len(X_tensor), batch_size):\n",
    "#         batch = X_tensor_scaled[i : i + batch_size].cuda()\n",
    "#         labels = y_tensor[i : i + batch_size].cuda()\n",
    "#         optimizer.zero_grad()\n",
    "#         loss = fe_model.forward_sl(batch, labels, fix_choice=True, hard=True)\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         # grad = torch.nn.utils.clip_grad_norm_(fe_model.parameters(), .1)\n",
    "\n",
    "#         if ema_loss is None: ema_loss = loss.item()\n",
    "#         ema_loss = 0.9 * ema_loss + 0.1 * loss.item()\n",
    "#         if i % (batch_size * 10) == 0: \n",
    "#             pbar.set_description_str(f'loss: {ema_loss:.4f}, lr: {scheduler.get_last_lr()[-1]:.3e}')\n",
    "#     pbar.set_description_str(f'loss: {ema_loss:.4f}, lr: {scheduler.get_last_lr()[-1]:.3e}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T12:32:39.153266Z",
     "iopub.status.busy": "2024-12-04T12:32:39.152456Z",
     "iopub.status.idle": "2024-12-04T12:32:39.160107Z",
     "shell.execute_reply": "2024-12-04T12:32:39.159245Z",
     "shell.execute_reply.started": "2024-12-04T12:32:39.153217Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "if np.any(np.isinf(train)):\n",
    "    train = train.replace([np.inf, -np.inf], np.nan)\n",
    "\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "    return np.where(oof_non_rounded < thresholds[0], 0,\n",
    "                    np.where(oof_non_rounded < thresholds[1], 1,\n",
    "                             np.where(oof_non_rounded < thresholds[2], 2, 3)))\n",
    "\n",
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T12:32:39.586747Z",
     "iopub.status.busy": "2024-12-04T12:32:39.586416Z",
     "iopub.status.idle": "2024-12-04T12:32:39.944882Z",
     "shell.execute_reply": "2024-12-04T12:32:39.943994Z",
     "shell.execute_reply.started": "2024-12-04T12:32:39.586717Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Losses: 4.3793, 12.6017, 5.7148\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fe_model.eval().cuda()\n",
    "with torch.no_grad():\n",
    "    total_loss1 = fe_model.forward_sl((X_tensor / X_scales).cuda(), y_tensor.cuda(), False, False)\n",
    "    total_loss2 = fe_model.forward_sl((X_tensor / X_scales).cuda(), y_tensor.cuda(), False, True)\n",
    "    total_loss3 = fe_model.forward_sl((X_tensor / X_scales).cuda(), y_tensor.cuda(), True, True)\n",
    "print(f'Losses: {total_loss1.item():.4f}, {total_loss2.item():.4f}, {total_loss3.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T12:32:48.711502Z",
     "iopub.status.busy": "2024-12-04T12:32:48.711145Z",
     "iopub.status.idle": "2024-12-04T12:32:48.739003Z",
     "shell.execute_reply": "2024-12-04T12:32:48.738253Z",
     "shell.execute_reply.started": "2024-12-04T12:32:48.711473Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "X1 = (X_tensor/X_scales).cpu().numpy()\n",
    "fe_model.eval().cuda()\n",
    "with torch.no_grad():\n",
    "    X2 = (X_tensor / X_scales).cuda()\n",
    "    new_feats = fe_model.forward(X2, True, True, 0.1)\n",
    "    X2 = torch.concatenate([X2, new_feats], dim=1).cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T12:32:53.777431Z",
     "iopub.status.busy": "2024-12-04T12:32:53.776671Z",
     "iopub.status.idle": "2024-12-04T12:32:53.782450Z",
     "shell.execute_reply": "2024-12-04T12:32:53.781408Z",
     "shell.execute_reply.started": "2024-12-04T12:32:53.777393Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\n",
    "XGB_Params = {\n",
    "    'learning_rate': 0.05,\n",
    "    'max_depth': 6,\n",
    "    'n_estimators': 200,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'reg_alpha': 1,  # Increased from 0.1\n",
    "    'reg_lambda': 5,  # Increased from 1\n",
    "    'random_state': SEED,\n",
    "    'tree_method': 'gpu_hist',\n",
    "\n",
    "}\n",
    "XGB_Model1 = XGBRegressor(**XGB_Params)\n",
    "XGB_Model2 = XGBRegressor(**XGB_Params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T12:32:54.393375Z",
     "iopub.status.busy": "2024-12-04T12:32:54.393001Z",
     "iopub.status.idle": "2024-12-04T12:32:54.847583Z",
     "shell.execute_reply": "2024-12-04T12:32:54.846806Z",
     "shell.execute_reply.started": "2024-12-04T12:32:54.393342Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8957070707070707"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_Model1.fit(X1, y_np)\n",
    "yp1 = XGB_Model1.predict(X1)\n",
    "(yp1.round(0) == y_np).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T12:32:55.738620Z",
     "iopub.status.busy": "2024-12-04T12:32:55.737923Z",
     "iopub.status.idle": "2024-12-04T12:32:56.214640Z",
     "shell.execute_reply": "2024-12-04T12:32:56.213775Z",
     "shell.execute_reply.started": "2024-12-04T12:32:55.738586Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9005050505050505"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XGB_Model1.fit(X2, y_np)\n",
    "yp2 = XGB_Model1.predict(X2)\n",
    "(yp2.round(0) == y_np).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T12:32:57.166714Z",
     "iopub.status.busy": "2024-12-04T12:32:57.165881Z",
     "iopub.status.idle": "2024-12-04T12:32:57.171932Z",
     "shell.execute_reply": "2024-12-04T12:32:57.171069Z",
     "shell.execute_reply.started": "2024-12-04T12:32:57.166680Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(fe_model_init.feat_generators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T12:33:38.703558Z",
     "iopub.status.busy": "2024-12-04T12:33:38.703115Z",
     "iopub.status.idle": "2024-12-04T12:33:38.753677Z",
     "shell.execute_reply": "2024-12-04T12:33:38.752863Z",
     "shell.execute_reply.started": "2024-12-04T12:33:38.703526Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df[\"Feat_0\"] = df[\"Physical-BMI\"] * df[\"Basic_Demos-Age\"]; trigger = True\n",
      "df[\"Feat_1\"] = df[\"PreInt_EduHx-computerinternet_hoursday\"] * df[\"Basic_Demos-Age\"]; trigger = True\n",
      "df[\"Feat_2\"] = df[\"Physical-BMI\"] * df[\"PreInt_EduHx-computerinternet_hoursday\"]; trigger = True\n",
      "df[\"Feat_3\"] = df[\"BIA-BIA_Fat\"] / df[\"BIA-BIA_BMI\"]; trigger = True\n",
      "df[\"Feat_4\"] = df[\"BIA-BIA_FFMI\"] / df[\"BIA-BIA_Fat\"]; trigger = True\n",
      "df[\"Feat_5\"] = df[\"BIA-BIA_FMI\"] / df[\"BIA-BIA_Fat\"]; trigger = True\n",
      "df[\"Feat_6\"] = df[\"BIA-BIA_LST\"] / df[\"BIA-BIA_TBW\"]; trigger = True\n",
      "df[\"Feat_7\"] = df[\"BIA-BIA_Fat\"] * df[\"BIA-BIA_BMR\"]; trigger = True\n",
      "df[\"Feat_8\"] = df[\"BIA-BIA_Fat\"] * df[\"BIA-BIA_DEE\"]; trigger = True\n",
      "df[\"Feat_9\"] = df[\"BIA-BIA_BMR\"] / df[\"Physical-Weight\"]; trigger = True\n",
      "df[\"Feat_10\"] = df[\"BIA-BIA_DEE\"] / df[\"Physical-Weight\"]; trigger = True\n",
      "df[\"Feat_11\"] = df[\"BIA-BIA_SMM\"] / df[\"Physical-Height\"]; trigger = True\n",
      "df[\"Feat_12\"] = df[\"BIA-BIA_SMM\"] / df[\"BIA-BIA_FMI\"]; trigger = True\n",
      "df[\"Feat_13\"] = df[\"BIA-BIA_TBW\"] / df[\"Physical-Weight\"]; trigger = True\n",
      "df[\"Feat_14\"] = df[\"BIA-BIA_ICW\"] / df[\"BIA-BIA_TBW\"]; trigger = True\n",
      "df[\"Feat_15\"] = df[\"Physical-BMI\"] * df[\"Physical-HeartRate\"]; trigger = True\n",
      "df[\"Feat_16\"] = df[\"BIA-BIA_Fat\"] * df[\"FGC-FGC_SRL\"]; trigger = False\n",
      "df[\"Feat_17\"] = df[\"Physical-Systolic_BP\"] / df[\"BIA-BIA_BMI\"]; trigger = True\n",
      "df[\"Feat_18\"] = df[\"Physical-BMI\"] * df[\"FGC-FGC_SRL\"]; trigger = True\n",
      "df[\"Feat_19\"] = df[\"BIA-BIA_Frame_num\"] / df[\"FGC-FGC_CU\"]; trigger = False\n",
      "dbg mse: 0.0000\n"
     ]
    }
   ],
   "source": [
    "print_features(fe_model_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-04T12:33:39.184939Z",
     "iopub.status.busy": "2024-12-04T12:33:39.184347Z",
     "iopub.status.idle": "2024-12-04T12:33:39.231055Z",
     "shell.execute_reply": "2024-12-04T12:33:39.230247Z",
     "shell.execute_reply.started": "2024-12-04T12:33:39.184907Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df[\"Feat_0\"] = df[\"BIA-BIA_Fat\"] * df[\"BIA-BIA_Fat\"]; trigger = True\n",
      "df[\"Feat_1\"] = df[\"BIA-BIA_LDM\"] * df[\"BIA-BIA_ECW\"]; trigger = True\n",
      "df[\"Feat_2\"] = df[\"Physical-Diastolic_BP\"] * df[\"BIA-BIA_Frame_num\"]; trigger = True\n",
      "df[\"Feat_3\"] = df[\"PAQ_A-PAQ_A_Total\"] / df[\"FGC-FGC_SRL\"]; trigger = True\n",
      "df[\"Feat_4\"] = df[\"BIA-BIA_BMR\"] / df[\"SDS-SDS_Total_T\"]; trigger = True\n",
      "df[\"Feat_5\"] = df[\"BIA-BIA_FMI\"] / df[\"Physical-Diastolic_BP\"]; trigger = True\n",
      "df[\"Feat_6\"] = df[\"FGC-FGC_PU_Zone\"] / df[\"FGC-FGC_SRR_Zone\"]; trigger = True\n",
      "df[\"Feat_7\"] = df[\"BIA-BIA_BMI\"] * df[\"BIA-BIA_Fat\"]; trigger = True\n",
      "df[\"Feat_8\"] = df[\"FGC-FGC_SRL\"] * df[\"BIA-BIA_SMM\"]; trigger = True\n",
      "df[\"Feat_9\"] = df[\"BIA-BIA_LDM\"] / df[\"FGC-FGC_SRL\"]; trigger = False\n",
      "df[\"Feat_10\"] = df[\"FGC-FGC_CU\"] / df[\"PreInt_EduHx-computerinternet_hoursday\"]; trigger = True\n",
      "df[\"Feat_11\"] = df[\"BIA-BIA_ECW\"] / df[\"BIA-BIA_FMI\"]; trigger = True\n",
      "df[\"Feat_12\"] = df[\"Fitness_Endurance-Time_Sec\"] / df[\"SDS-SDS_Total_Raw\"]; trigger = False\n",
      "df[\"Feat_13\"] = df[\"FGC-FGC_GSD_Zone\"] / df[\"FGC-FGC_TL_Zone\"]; trigger = True\n",
      "df[\"Feat_14\"] = df[\"Physical-Waist_Circumference\"] / df[\"FGC-FGC_SRL_Zone\"]; trigger = True\n",
      "df[\"Feat_15\"] = df[\"FGC-FGC_GSD_Zone\"] * df[\"BIA-BIA_FMI\"]; trigger = False\n",
      "df[\"Feat_16\"] = df[\"FGC-FGC_SRL\"] * df[\"FGC-FGC_SRL\"]; trigger = False\n",
      "df[\"Feat_17\"] = df[\"Fitness_Endurance-Time_Sec\"] / df[\"FGC-FGC_GSND_Zone\"]; trigger = False\n",
      "df[\"Feat_18\"] = df[\"FGC-FGC_GSND_Zone\"] * df[\"BIA-BIA_FMI\"]; trigger = False\n",
      "df[\"Feat_19\"] = df[\"FGC-FGC_GSND\"] / df[\"FGC-FGC_SRR\"]; trigger = False\n",
      "dbg mse: 0.0000\n"
     ]
    }
   ],
   "source": [
    "print_features(fe_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9643020,
     "sourceId": 81933,
     "sourceType": "competition"
    },
    {
     "datasetId": 921302,
     "sourceId": 7453542,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30776,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
