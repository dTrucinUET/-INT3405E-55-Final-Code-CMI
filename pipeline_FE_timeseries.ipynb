{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b61f3bae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:09:18.078035Z",
     "iopub.status.busy": "2024-12-23T14:09:18.077752Z",
     "iopub.status.idle": "2024-12-23T14:09:26.783038Z",
     "shell.execute_reply": "2024-12-23T14:09:26.782329Z"
    },
    "papermill": {
     "duration": 8.714876,
     "end_time": "2024-12-23T14:09:26.784467",
     "exception": false,
     "start_time": "2024-12-23T14:09:18.069591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from scipy.optimize import minimize\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import polars as pl\n",
    "from colorama import Fore, Style\n",
    "from IPython.display import clear_output\n",
    "import warnings\n",
    "from lightgbm import LGBMRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.impute import SimpleImputer\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import sys\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "from pathlib import Path\n",
    "import polars as pl\n",
    "import datetime\n",
    "import yaml\n",
    "import gc\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.options.display.max_columns = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b63e527",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-12-23T14:09:26.799030Z",
     "iopub.status.busy": "2024-12-23T14:09:26.798531Z",
     "iopub.status.idle": "2024-12-23T14:09:26.807096Z",
     "shell.execute_reply": "2024-12-23T14:09:26.806558Z"
    },
    "papermill": {
     "duration": 0.016797,
     "end_time": "2024-12-23T14:09:26.808297",
     "exception": false,
     "start_time": "2024-12-23T14:09:26.791500",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def seed_everything(seed):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "\n",
    "SEED = 42\n",
    "n_splits = 5\n",
    "seed_everything(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ced9379",
   "metadata": {
    "papermill": {
     "duration": 0.006337,
     "end_time": "2024-12-23T14:09:26.821232",
     "exception": false,
     "start_time": "2024-12-23T14:09:26.814895",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a5f5c3c",
   "metadata": {
    "papermill": {
     "duration": 0.006272,
     "end_time": "2024-12-23T14:09:26.833888",
     "exception": false,
     "start_time": "2024-12-23T14:09:26.827616",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Feature engineer for time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fc8156",
   "metadata": {
    "papermill": {
     "duration": 0.006219,
     "end_time": "2024-12-23T14:09:26.846550",
     "exception": false,
     "start_time": "2024-12-23T14:09:26.840331",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Method 1: Autoencoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dc6d5110",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:09:26.860565Z",
     "iopub.status.busy": "2024-12-23T14:09:26.860329Z",
     "iopub.status.idle": "2024-12-23T14:09:26.869185Z",
     "shell.execute_reply": "2024-12-23T14:09:26.868576Z"
    },
    "papermill": {
     "duration": 0.017041,
     "end_time": "2024-12-23T14:09:26.870376",
     "exception": false,
     "start_time": "2024-12-23T14:09:26.853335",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, input_dim, encoding_dim):\n",
    "        super(AutoEncoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_dim, encoding_dim*3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(encoding_dim*3, encoding_dim*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(encoding_dim*2, encoding_dim),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(encoding_dim, encoding_dim*2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(encoding_dim*2, encoding_dim*3),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(encoding_dim*3, input_dim),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n",
    "\n",
    "\n",
    "def perform_autoencoder(df, encoding_dim=50, epochs=50, batch_size=32):\n",
    "    scaler = StandardScaler()\n",
    "    df_scaled = scaler.fit_transform(df)\n",
    "    \n",
    "    data_tensor = torch.FloatTensor(df_scaled)\n",
    "    \n",
    "    input_dim = data_tensor.shape[1]\n",
    "    autoencoder = AutoEncoder(input_dim, encoding_dim)\n",
    "    \n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(autoencoder.parameters())\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        for i in range(0, len(data_tensor), batch_size):\n",
    "            batch = data_tensor[i : i + batch_size]\n",
    "            optimizer.zero_grad()\n",
    "            reconstructed = autoencoder(batch)\n",
    "            loss = criterion(reconstructed, batch)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "        if (epoch + 1) % 50 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}]')    \n",
    "    return autoencoder, scaler\n",
    "\n",
    "def encode_data(autoencoder, scaler, df):\n",
    "    df_scaled = scaler.transform(df)\n",
    "    data_tensor = torch.FloatTensor(df_scaled)\n",
    "    with torch.no_grad():\n",
    "        encoded_data = autoencoder.encoder(data_tensor).numpy()\n",
    "\n",
    "    df_encoded = pd.DataFrame(encoded_data, columns=[f'Enc_{i + 1}' for i in range(encoded_data.shape[1])])\n",
    "    return df_encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee6b6d5",
   "metadata": {
    "papermill": {
     "duration": 0.006172,
     "end_time": "2024-12-23T14:09:26.882883",
     "exception": false,
     "start_time": "2024-12-23T14:09:26.876711",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Method 2: External knowledge\n",
    "\n",
    "First, prepare the features used in my sleep detection model. Please refer to the implementation by [@tatamikenn](https://www.kaggle.com/tatamikenn) [here](https://www.kaggle.com/code/tatamikenn/sleep-hdcza-a-pure-heuristic-approach-lb-0-447).\n",
    "\n",
    "This pipeline processes accelerometer data for sleep detection, utilizing time-series datasets. It generates features to identify sleep episodes, static periods, and motion patterns, inspired by @tatamikenn's implementation.\n",
    "\n",
    "-  `transform`: this function processes input data to generate features for analysis. It breaks down the timestamp into components like year, month, day, hour, and weekday. It also groups data by night, adjusting the timestamp if necessary, and creates a unique `night_group` identifier for each night. Additionally, a cumulative step count (norm_step) is computed for each group to facilitate sequential analysis.\n",
    "\n",
    "- `transform_series`: this function enhances the transform function by adding a new feature: detecting clipped ENMO values. It flags instances where the enmo (motion metric) is zero, marking potential data quality issues.\n",
    "\n",
    "- `transform_events`: this function processes event data by adding a night column and pivoting the data. The events are rearranged by `series_id`, `group_id`, and night to simplify time-series analysis.\n",
    "\n",
    "- `add_feature`: this function generates advanced features for sleep detection, including:\n",
    "    - Difference Features: Computes the differences in anglez (angular motion) and enmo (motion magnitude).\n",
    "    - Rolling Median: Calculates rolling medians of anglez_diff and enmo_diff over a 5-minute window.\n",
    "    - Critical Threshold: Determines static periods by evaluating anglez_diff variability over a day.\n",
    "    - Static and Sleep Blocks: Flags periods with minimal motion (is_static) and identifies sleep blocks over 30-minute windows.\n",
    "    - Sleep Episodes: Detects continuous sleep episodes, identifies the longest one, and flags interruptions in sleep.\n",
    "\n",
    "-  `create_heuristic`: the main function processes raw data files by converting timestamps and applying transformations. It calls the transform_series function to prepare the data and the add_feature function to generate sleep-related features. Finally, it saves the processed data into .parquet files for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5263ea2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:09:26.896104Z",
     "iopub.status.busy": "2024-12-23T14:09:26.895894Z",
     "iopub.status.idle": "2024-12-23T14:09:26.898871Z",
     "shell.execute_reply": "2024-12-23T14:09:26.898224Z"
    },
    "papermill": {
     "duration": 0.010935,
     "end_time": "2024-12-23T14:09:26.900043",
     "exception": false,
     "start_time": "2024-12-23T14:09:26.889108",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "MAX_FILE = 2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "457f0797",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:09:26.913629Z",
     "iopub.status.busy": "2024-12-23T14:09:26.913417Z",
     "iopub.status.idle": "2024-12-23T14:09:26.929904Z",
     "shell.execute_reply": "2024-12-23T14:09:26.929234Z"
    },
    "papermill": {
     "duration": 0.02483,
     "end_time": "2024-12-23T14:09:26.931138",
     "exception": false,
     "start_time": "2024-12-23T14:09:26.906308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transform(df, night_offset=20):\n",
    "    return (\n",
    "        df.with_columns(\n",
    "            [\n",
    "                (pl.col(\"timestamp\").dt.year() - 2000).cast(pl.Int8).alias(\"year\"),\n",
    "                pl.col(\"timestamp\").dt.month().cast(pl.Int8).alias(\"month\"),\n",
    "                pl.col(\"timestamp\").dt.day().cast(pl.Int8).alias(\"day\"),\n",
    "                pl.col(\"timestamp\").dt.hour().cast(pl.Int8).alias(\"hour\"),\n",
    "                pl.col(\"timestamp\").dt.minute().cast(pl.Int8).alias(\"minute\"),\n",
    "                pl.col(\"timestamp\").dt.second().cast(pl.Int8).alias(\"second\"),\n",
    "                pl.col(\"timestamp\").dt.weekday().cast(pl.Int8).alias(\"weekday\"),\n",
    "            ]\n",
    "        )\n",
    "        .with_columns( \n",
    "            pl.when(pl.col(\"hour\") < night_offset)\n",
    "            .then(pl.col(\"timestamp\"))\n",
    "            .otherwise(pl.col(\"timestamp\") + pl.duration(days=1))\n",
    "            .dt.date()\n",
    "            .alias(\"night_group\"),\n",
    "        )\n",
    "        .with_columns(\n",
    "            [\n",
    "                (\n",
    "                    pl.col(\"series_id\") + pl.lit(\"_\") + pl.col(\"night_group\").cast(pl.Datetime).dt.strftime(\"%Y%m%d\")\n",
    "                ).alias(\"group_id\"),\n",
    "            ]\n",
    "        )\n",
    "        .with_columns(\n",
    "            [\n",
    "                pl.col(\"timestamp\").cum_count().over(\"group_id\").alias(\"norm_step\"),\n",
    "            ]\n",
    "        )\n",
    "        .drop([\"night_group\"])\n",
    "    )\n",
    "\n",
    "\n",
    "def transform_series(df):\n",
    "    return transform(df).with_columns(\n",
    "        [\n",
    "            (pl.col(\"enmo\") == 0).alias(\"is_enmo_clipped\"),\n",
    "        ]\n",
    "    )\n",
    "\n",
    "\n",
    "def transform_events(df):\n",
    "    return (\n",
    "        transform(df)\n",
    "        .with_columns(\n",
    "            [\n",
    "                pl.col(\"night\").cast(pl.UInt32).alias(\"night\"),\n",
    "            ]\n",
    "        )\n",
    "        .pivot([\"step\", \"timestamp\", \"tz_offset\"], [\"series_id\", \"group_id\", \"night\"], \"event\")\n",
    "    )\n",
    "\n",
    "\n",
    "def add_feature(\n",
    "    df,\n",
    "    day_group_col=\"group_id\",\n",
    "    term1=(5 * 60) // 5,\n",
    "    term2=(30 * 60) // 5,\n",
    "    term3=(60 * 60) // 5,\n",
    "    min_threshold=0.005,\n",
    "    max_threshold=0.04,\n",
    "    center=True,\n",
    "):\n",
    "    return (\n",
    "        df.with_columns(\n",
    "            [\n",
    "                pl.col(\"anglez\").diff(1).abs().alias(\"anglez_diff\"),\n",
    "                pl.col(\"enmo\").diff(1).abs().alias(\"enmo_diff\"),\n",
    "            ]\n",
    "        )\n",
    "        .with_columns(\n",
    "            [\n",
    "                pl.col(\"anglez_diff\")\n",
    "                .rolling_median(term1, center=center)  # 5 min window\n",
    "                .alias(\"anglez_diff_median_5min\"),\n",
    "                pl.col(\"enmo_diff\")\n",
    "                .rolling_median(term1, center=center)  # 5 min window\n",
    "                .alias(\"enmo_diff_median_5min\"),\n",
    "            ]\n",
    "        )\n",
    "        .with_columns(\n",
    "            [\n",
    "                pl.col(\"anglez_diff_median_5min\")\n",
    "                .quantile(0.1)\n",
    "                .clip(min_threshold, max_threshold)\n",
    "                .over(day_group_col)\n",
    "                .alias(\"critical_threshold\")\n",
    "            ]\n",
    "        )\n",
    "        .with_columns([(pl.col(\"anglez_diff_median_5min\") < pl.col(\"critical_threshold\") * 15).alias(\"is_static\")])\n",
    "        .with_columns(\n",
    "            [\n",
    "                pl.col(\"is_static\").cast(pl.Int32).rolling_sum(term2, center=center).alias(\"is_static_sum_30min\"),\n",
    "            ]\n",
    "        )\n",
    "        .with_columns([(pl.col(\"is_static_sum_30min\") == ((30 * 60) // 5)).alias(\"tmp\")])\n",
    "        .with_columns(\n",
    "            [\n",
    "                pl.col(\"tmp\").shift(term2 // 2).alias(\"tmp_left\"),\n",
    "                pl.col(\"tmp\").shift(-(term2 // 2)).alias(\"tmp_right\"),\n",
    "            ]\n",
    "        )\n",
    "        .with_columns(\n",
    "            [\n",
    "                (pl.col(\"tmp_left\") | pl.col(\"tmp_right\")).alias(\"is_sleep_block\"),\n",
    "            ]\n",
    "        )\n",
    "        .drop([\"tmp\", \"tmp_left\", \"tmp_right\"])\n",
    "        .with_columns([pl.col(\"is_sleep_block\").not_().alias(\"is_gap\")])\n",
    "        .with_columns([pl.col(\"is_gap\").cast(pl.Int32).rolling_sum(term3, center=center).alias(\"gap_length\")])\n",
    "        .with_columns([(pl.col(\"gap_length\") == term3).alias(\"tmp\")])\n",
    "        .with_columns(\n",
    "            [\n",
    "                pl.col(\"tmp\").shift(term3 // 2).alias(\"tmp_left\"),\n",
    "                pl.col(\"tmp\").shift(-(term3 // 2)).alias(\"tmp_right\"),\n",
    "            ]\n",
    "        )\n",
    "        .with_columns(\n",
    "            [\n",
    "                (pl.col(\"tmp_left\") | pl.col(\"tmp_right\")).alias(\"is_large_gap\"),\n",
    "            ]\n",
    "        )\n",
    "        .drop([\"tmp\", \"tmp_left\", \"tmp_right\"])\n",
    "        .with_columns([pl.col(\"is_large_gap\").not_().alias(\"is_sleep_episode\")])\n",
    "        #\n",
    "        # extract longest sleep episode\n",
    "        #\n",
    "        .with_columns(\n",
    "            [\n",
    "                # extract false->true transition\n",
    "                (\n",
    "                    (\n",
    "                        pl.col(\"is_sleep_episode\")\n",
    "                        & pl.col(\"is_sleep_episode\").shift(1, fill_value=pl.lit(False)).not_()\n",
    "                    )\n",
    "                    .cum_sum()\n",
    "                    .over(\"group_id\")\n",
    "                ).alias(\"sleep_episode_id\")\n",
    "            ]\n",
    "        )\n",
    "        .with_columns(\n",
    "            [pl.col(\"is_sleep_episode\").sum().over([\"group_id\", \"sleep_episode_id\"]).alias(\"sleep_episode_length\")]\n",
    "        )\n",
    "        .with_columns([pl.col(\"sleep_episode_length\").max().over([\"group_id\"]).alias(\"max_sleep_episode_length\")])\n",
    "        .with_columns(\n",
    "            [\n",
    "                (\n",
    "                    pl.col(\"is_sleep_episode\") & (pl.col(\"sleep_episode_length\") == pl.col(\"max_sleep_episode_length\"))\n",
    "                ).alias(\"is_longest_sleep_episode\")\n",
    "            ]\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "use_columns = [\n",
    "    \"series_id\",\n",
    "    \"step\",\n",
    "    \"is_longest_sleep_episode\",\n",
    "    \"is_sleep_block\",\n",
    "    \"is_gap\",\n",
    "    \"is_large_gap\",\n",
    "    \"is_sleep_episode\",\n",
    "    \"is_static\",\n",
    "]\n",
    "\n",
    "def create_heuristic(paths, train_or_test):\n",
    "    i = 0\n",
    "    for path in tqdm(paths):\n",
    "        i += 1\n",
    "        if (i == MAX_FILE):\n",
    "            break\n",
    "        sdf = pl.read_parquet(path)\n",
    "    \n",
    "        # dummy timestamp\n",
    "        sdf = sdf.with_columns((pl.col(\"time_of_day\") == 0).cast(pl.Int32).cum_sum().alias(\"day_offset\"))\n",
    "        sdf = sdf.with_columns(\n",
    "            (\n",
    "                datetime.datetime(2020, 1, 1)\n",
    "                + (pl.col(\"day_offset\") * 86400_000_000 + pl.col(\"time_of_day\") / 1000).cast(pl.Duration(\"us\"))\n",
    "            ).alias(\"timestamp\")\n",
    "        )\n",
    "    \n",
    "        sdf = sdf.with_columns(pl.lit(path.split(\"/\")[-2]).alias(\"series_id\"))\n",
    "        sdf = sdf.sort(\"step\")\n",
    "        sdf = transform_series(sdf)\n",
    "        sdf = add_feature(sdf)\n",
    "        sdf = sdf[use_columns].fill_null(False)\n",
    "    \n",
    "        sidf = path.split(\"/\")[-2]\n",
    "        save_path = f\"/kaggle/working/heuristic_features/{train_or_test}/{sidf}.parquet\"\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        sdf.write_parquet(save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e2300bc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:09:26.944606Z",
     "iopub.status.busy": "2024-12-23T14:09:26.944368Z",
     "iopub.status.idle": "2024-12-23T14:09:37.466454Z",
     "shell.execute_reply": "2024-12-23T14:09:37.465519Z"
    },
    "papermill": {
     "duration": 10.530745,
     "end_time": "2024-12-23T14:09:37.468151",
     "exception": false,
     "start_time": "2024-12-23T14:09:26.937406",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if True:\n",
    "    sys.path.append(\"/kaggle/input/cmi-2023-src\")\n",
    "    from consts import ANGLEZ_MEAN, ANGLEZ_STD, ENMO_MEAN, ENMO_STD\n",
    "    from torch_models.dataset import ZzzPatchDataset\n",
    "    from torch_models.models import ZzzConv1dGRUModel, ZzzTransformerGRUModel, ZzzWaveGRUModel\n",
    "\n",
    "    from utils.feature_contena import Features\n",
    "    from utils.lightning_utils import MyLightningDataModule, MyLightningModule\n",
    "    from utils.set_seed import seed_base_torch\n",
    "    from utils.torch_template import EnsembleModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "25517f3d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:09:37.483088Z",
     "iopub.status.busy": "2024-12-23T14:09:37.482463Z",
     "iopub.status.idle": "2024-12-23T14:09:37.500627Z",
     "shell.execute_reply": "2024-12-23T14:09:37.499945Z"
    },
    "papermill": {
     "duration": 0.026627,
     "end_time": "2024-12-23T14:09:37.501718",
     "exception": false,
     "start_time": "2024-12-23T14:09:37.475091",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def detection(paths=f\"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet/id=*/part-0.parquet\", train_or_test=\"train\"):\n",
    "    MODEL_NAME = \"patch_transformer_gru\"\n",
    "    \n",
    "    PACKAGE_DIR = Path(\"/kaggle/input/cmi-2023-src\")\n",
    "    CFG = yaml.safe_load(open(PACKAGE_DIR / \"config.yaml\", \"r\"))\n",
    "    BLOCK_SIZE = CFG[MODEL_NAME][\"execution\"][\"block_size\"]\n",
    "    \n",
    "    CFG[\"output_dir\"] = f\"/kaggle/input/cmi-2023-output/{CFG[MODEL_NAME]['execution']['best_exp_id']}\"\n",
    "    \n",
    "    seed_base_torch(CFG[\"env\"][\"seed\"])\n",
    "    \n",
    "    DEVICE = \"cuda\"\n",
    "    \n",
    "    files = glob(\n",
    "        paths\n",
    "    )\n",
    "    \n",
    "    features = Features()\n",
    "    features.add_num_features([\"anglez\", \"enmo\"])\n",
    "    features.add_num_features([\"anglez_diff\", \"enmo_diff\"])\n",
    "    features.add_num_features([\"same_count\"])\n",
    "    features.add_num_features([\"large_diff_count\"])\n",
    "    features.add_num_features([\"same_count_shift_plus\", \"same_count_shift_minus\"])\n",
    "    features.add_num_features([\"is_longest_sleep_episode\", \"is_sleep_block\"])\n",
    "    \n",
    "    # transformer + gru\n",
    "    model = ZzzTransformerGRUModel(\n",
    "        max_len=BLOCK_SIZE // CFG[MODEL_NAME][\"execution\"][\"patch_size\"],\n",
    "        input_numerical_size=len(features.all_features()) * CFG[MODEL_NAME][\"execution\"][\"patch_size\"],\n",
    "        **CFG[MODEL_NAME][\"params\"],\n",
    "    )\n",
    "    trn_models = [\n",
    "        MyLightningModule.load_from_checkpoint(\n",
    "            os.path.join(\"/kaggle/input/cmi-2023-output/exp_160\", f\"logs/best_model_fold{fold}.ckpt\"),\n",
    "            model=model,\n",
    "            map_location=torch.device(DEVICE),\n",
    "        ).to(DEVICE)\n",
    "        for fold in range(5 if len(files) > 100 else 1)\n",
    "    ]\n",
    "    \n",
    "    models = trn_models\n",
    "    model = EnsembleModel(models).to(DEVICE)\n",
    "    model.eval()\n",
    "    \n",
    "    all_oof_dfs = []\n",
    "    i = 0\n",
    "    for file in tqdm(files):\n",
    "        # load file\n",
    "        i += 1\n",
    "        if (i == MAX_FILE):\n",
    "            break\n",
    "        df = pd.read_parquet(file)\n",
    "        if len(df) < BLOCK_SIZE:\n",
    "            continue\n",
    "        time_of_days = df[\"time_of_day\"].values\n",
    "    \n",
    "        # same_count\n",
    "        DAY_STEPS = 12 * 60 * 24\n",
    "        n_days = int(len(df) // DAY_STEPS) + 1\n",
    "        df[\"same_count\"] = 0\n",
    "        for day in range(-n_days, n_days + 1):\n",
    "            if day == 0:\n",
    "                continue\n",
    "            df[\"_anglez_diff\"] = df[\"anglez\"].diff(DAY_STEPS * day)\n",
    "            df[\"_anglez_diff\"] = df[\"_anglez_diff\"].fillna(1)\n",
    "            df[\"same_count\"] += (df[\"_anglez_diff\"] == 0).astype(int)\n",
    "        df[\"same_count\"] = (df[\"same_count\"].clip(0, 5) - 2.5) / 2.5\n",
    "    \n",
    "        SHIFT_STEPS = 12 * 60 * 6  # 6h\n",
    "        df[\"same_count_shift_plus\"] = df[\"same_count\"].shift(SHIFT_STEPS).fillna(1.0).astype(np.float16)\n",
    "        df[\"same_count_shift_minus\"] = df[\"same_count\"].shift(-SHIFT_STEPS).fillna(1.0).astype(np.float16)\n",
    "    \n",
    "        # features\n",
    "        df[\"anglez_diffabs\"] = df[\"anglez\"].diff().abs().fillna(0)\n",
    "        df[\"large_diff\"] = (df[\"anglez_diffabs\"] > 5).astype(int)\n",
    "        df[\"large_diff_count\"] = df[\"large_diff\"].rolling(10, center=True).mean().fillna(0)\n",
    "        df[\"large_diff_count\"] = (df[\"large_diff_count\"] - 0.5) * 2\n",
    "    \n",
    "        # normalize\n",
    "        df[\"anglez\"] = (df[\"anglez\"] - ANGLEZ_MEAN) / ANGLEZ_STD\n",
    "        df[\"enmo\"] = (df[\"enmo\"] - ENMO_MEAN) / ENMO_STD\n",
    "        df[\"anglez_diff\"] = df[\"anglez\"].diff().fillna(0)\n",
    "        df[\"enmo_diff\"] = df[\"enmo\"].diff().fillna(0)\n",
    "    \n",
    "        # heuristic_features by @bilzard\n",
    "        sid = file.split(\"/\")[-2]\n",
    "        df[\"series_id\"] = sid\n",
    "        path = f\"/kaggle/working/heuristic_features/{train_or_test}/{sid}.parquet\"\n",
    "        hdf = pd.read_parquet(path)\n",
    "        df = pd.concat([df, hdf.drop(columns=[\"series_id\", \"step\"])], axis=1)\n",
    "        df[[\"is_longest_sleep_episode\", \"is_sleep_block\"]] = df[[\"is_longest_sleep_episode\", \"is_sleep_block\"]] * 2 - 1\n",
    "    \n",
    "        # split\n",
    "        dfs = []\n",
    "        df = df.sort_values(\"step\").reset_index(drop=True)\n",
    "        for start in range(0, len(df), BLOCK_SIZE // 8):\n",
    "            end = start + BLOCK_SIZE\n",
    "            if end > len(df):\n",
    "                end = len(df) - len(df) % CFG[MODEL_NAME][\"execution\"][\"patch_size\"]\n",
    "                start = end - BLOCK_SIZE\n",
    "                assert start >= 0\n",
    "            assert df.iloc[start][\"step\"] % CFG[MODEL_NAME][\"execution\"][\"patch_size\"] == 0\n",
    "            dfs.append(df.iloc[start:end])\n",
    "        gc.collect()\n",
    "    \n",
    "        # inference\n",
    "        train_dataset = ZzzPatchDataset(\n",
    "            dfs, mode=\"test\", features=features, patch_size=CFG[MODEL_NAME][\"execution\"][\"patch_size\"]\n",
    "        )\n",
    "        valid_dataset = ZzzPatchDataset(\n",
    "            dfs, mode=\"test\", features=features, patch_size=CFG[MODEL_NAME][\"execution\"][\"patch_size\"]\n",
    "        )\n",
    "        data_module = MyLightningDataModule(train_dataset, valid_dataset, batch_size=64)\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for X in data_module.val_dataloader():\n",
    "                pred = torch.sigmoid(model(X.to(\"cuda\"))).detach().cpu().numpy() * 10\n",
    "                preds.append(pred)\n",
    "    \n",
    "        oof_dfs = []\n",
    "        for pred, df in zip(np.vstack(preds), dfs):\n",
    "            df = df.iloc[\n",
    "                CFG[MODEL_NAME][\"execution\"][\"patch_size\"] // 2 : len(df) : CFG[MODEL_NAME][\"execution\"][\"patch_size\"]\n",
    "            ].reset_index(drop=True)\n",
    "            df[[\"wakeup_oof\", \"onset_oof\"]] = pred\n",
    "            oof_dfs.append(df[[\"series_id\", \"step\", \"wakeup_oof\", \"onset_oof\"]])\n",
    "    \n",
    "        oof_df = pd.concat(oof_dfs)\n",
    "        oof_df = oof_df.groupby([\"series_id\", \"step\"]).mean().reset_index().sort_values([\"series_id\", \"step\"])\n",
    "        oof_df = oof_df[[\"series_id\", \"step\", \"wakeup_oof\", \"onset_oof\"]]\n",
    "        oof_df[\"step\"] = oof_df[\"step\"].astype(int)\n",
    "    \n",
    "        del preds, oof_dfs\n",
    "        gc.collect()\n",
    "    \n",
    "        train = oof_df.reset_index(drop=True)\n",
    "        train[\"time_of_day\"] = time_of_days[\n",
    "            CFG[MODEL_NAME][\"execution\"][\"patch_size\"] // 2 :: CFG[MODEL_NAME][\"execution\"][\"patch_size\"]\n",
    "        ][: len(train)]\n",
    "        all_oof_dfs.append(train[[\"series_id\", \"step\", \"wakeup_oof\", \"onset_oof\", \"time_of_day\"]])\n",
    "        # del dfs, df\n",
    "        gc.collect()\n",
    "\n",
    "    # save\n",
    "    for df in tqdm(all_oof_dfs):\n",
    "        save_path = f\"/kaggle/working/features/sleep_detection/{train_or_test}/{df['series_id'].iloc[0]}.parquet\"\n",
    "        os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "        df.to_parquet(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "45578d1e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:09:37.515258Z",
     "iopub.status.busy": "2024-12-23T14:09:37.515019Z",
     "iopub.status.idle": "2024-12-23T14:09:37.518056Z",
     "shell.execute_reply": "2024-12-23T14:09:37.517431Z"
    },
    "papermill": {
     "duration": 0.011121,
     "end_time": "2024-12-23T14:09:37.519279",
     "exception": false,
     "start_time": "2024-12-23T14:09:37.508158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_of_day_max = 86400000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51aa2215",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:09:37.532960Z",
     "iopub.status.busy": "2024-12-23T14:09:37.532758Z",
     "iopub.status.idle": "2024-12-23T14:09:37.548528Z",
     "shell.execute_reply": "2024-12-23T14:09:37.547900Z"
    },
    "papermill": {
     "duration": 0.024045,
     "end_time": "2024-12-23T14:09:37.549665",
     "exception": false,
     "start_time": "2024-12-23T14:09:37.525620",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def feature_engineering(paths=\"/kaggle/working/features/sleep_detection/train/*.parquet\", data_paths=\"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\", train_or_test=\"train\"):\n",
    "    features = []\n",
    "    debug_count = 0\n",
    "    all_files = sorted(glob(paths))\n",
    "    i = 0\n",
    "    for file in tqdm(all_files):\n",
    "        i += 1\n",
    "        if (i == MAX_FILE):\n",
    "            break\n",
    "        df = pl.read_parquet(file)\n",
    "        df = df.with_columns(pl.col(\"step\").cast(pl.UInt32)).drop(\"time_of_day\")\n",
    "        sid = df[\"series_id\"][0]\n",
    "    \n",
    "        sensor_df = pl.read_parquet(\n",
    "            f\"{data_paths}/{sid}/part-0.parquet\"\n",
    "        ).with_columns((pl.col(\"time_of_day\") == 0).cum_sum().alias(\"day\"))\n",
    "    \n",
    "        feature = {\n",
    "            \"id\": sid,\n",
    "            \"length\": df.shape[0],\n",
    "            \"day\": sensor_df[\"relative_date_PCIAT\"].max() - sensor_df[\"relative_date_PCIAT\"].min(),\n",
    "        }\n",
    "    \n",
    "        # skip if time step is not 5sec\n",
    "        diffs = sensor_df[\"time_of_day\"].diff().drop_nulls().unique()\n",
    "        if set(diffs) != set([-86395000000000, 5000000000]):\n",
    "            features.append(feature)\n",
    "            continue\n",
    "    \n",
    "        sensor_df = (\n",
    "            sensor_df.join(df, on=\"step\", how=\"left\")\n",
    "            .sort(\"step\")\n",
    "            .with_columns(\n",
    "                pl.col(\"onset_oof\").interpolate(),\n",
    "                pl.col(\"wakeup_oof\").interpolate(),\n",
    "            )\n",
    "        )\n",
    "    \n",
    "        # onset = 15:00~3:00, wakeup = 3:00~15:00\n",
    "        onset_start = time_of_day_max / 24 * 15  # 15:00\n",
    "        onset_end = time_of_day_max / 24 * 3  # 3:00\n",
    "        sensor_df = sensor_df.with_columns(\n",
    "            ((pl.col(\"time_of_day\") > onset_start) | (pl.col(\"time_of_day\") < onset_end)).alias(\"onset_duration\"),\n",
    "        ).with_columns(\n",
    "            pl.col(\"onset_duration\").cast(pl.Int32).diff().fill_null(0).abs().cum_sum().alias(\"onset_wakeup_duration\")\n",
    "        )\n",
    "    \n",
    "        # get sleep period\n",
    "        sleep_info = []\n",
    "        for _, df in sensor_df.group_by(\"onset_wakeup_duration\", maintain_order=True):\n",
    "            is_onset = df[\"onset_duration\"][0]\n",
    "            if is_onset:\n",
    "                max_idx = df[\"onset_oof\"].arg_max()\n",
    "                if max_idx is None:\n",
    "                    continue\n",
    "                max_score = df[\"onset_oof\"][max_idx]\n",
    "                step = df[\"step\"][max_idx]\n",
    "    \n",
    "                # date\n",
    "                start_time = df[\"time_of_day\"][0] / time_of_day_max * 24\n",
    "                if start_time >= 15:\n",
    "                    day = df[\"day\"][0]\n",
    "                    week_day = df[\"weekday\"][0]\n",
    "                else:\n",
    "                    day = df[\"day\"][0] - 1\n",
    "                    week_day = df[\"weekday\"][0] - 1\n",
    "                    if week_day == 0:\n",
    "                        week_day = 7\n",
    "            else:\n",
    "                max_idx = df[\"wakeup_oof\"].arg_max()\n",
    "                if max_idx is None:\n",
    "                    continue\n",
    "                max_score = df[\"wakeup_oof\"][max_idx]\n",
    "                step = df[\"step\"][max_idx]\n",
    "    \n",
    "                # date\n",
    "                start_time = df[\"time_of_day\"][0] / time_of_day_max * 24\n",
    "                day = df[\"day\"][0] - 1\n",
    "                week_day = df[\"weekday\"][0] - 1\n",
    "    \n",
    "            info = {\n",
    "                \"day\": day,\n",
    "                \"weekday\": week_day,\n",
    "                \"type\": \"onset\" if is_onset else \"wakeup\",\n",
    "                \"step\": step,\n",
    "                \"max_score\": max_score,\n",
    "                \"time\": df[\"time_of_day\"][max_idx] / time_of_day_max * 24,\n",
    "            }\n",
    "            sleep_info.append(info)\n",
    "        sleep_df = pl.DataFrame(sleep_info)\n",
    "    \n",
    "        # merge\n",
    "        sleep_df = (\n",
    "            sleep_df.filter(pl.col(\"type\") == \"onset\")\n",
    "            .drop(\"type\")\n",
    "            .rename(\n",
    "                {\n",
    "                    \"max_score\": \"onset_score\",\n",
    "                    \"step\": \"onset_step\",\n",
    "                    \"time\": \"onset_time\",\n",
    "                }\n",
    "            )\n",
    "            .join(\n",
    "                sleep_df.filter(pl.col(\"type\") == \"wakeup\")\n",
    "                .drop([\"type\", \"weekday\"])\n",
    "                .rename(\n",
    "                    {\n",
    "                        \"max_score\": \"wakeup_score\",\n",
    "                        \"step\": \"wakeup_step\",\n",
    "                        \"time\": \"wakeup_time\",\n",
    "                    }\n",
    "                ),\n",
    "                on=\"day\",\n",
    "            )\n",
    "        ).select(\n",
    "            [\"day\", \"weekday\", \"onset_time\", \"wakeup_time\", \"onset_step\", \"wakeup_step\", \"onset_score\", \"wakeup_score\"]\n",
    "        )\n",
    "    \n",
    "        # feature engineering\n",
    "        sleep_lengths = []  # wakeup - onset\n",
    "        sleep_enmo_mean = []  \n",
    "        sleep_enmo_std = []  \n",
    "        sleep_light_mean = []\n",
    "        sleep_light_std = [] \n",
    "        for i in range(len(sleep_df)):\n",
    "            # sleep period\n",
    "            start = sleep_df[\"onset_step\"][i]\n",
    "            end = sleep_df[\"wakeup_step\"][i]\n",
    "            if sleep_df[\"onset_score\"][i] < 1 or sleep_df[\"wakeup_score\"][i] < 1:\n",
    "                sleep_lengths.append(np.nan)\n",
    "                sleep_enmo_mean.append(np.nan)\n",
    "                sleep_enmo_std.append(np.nan)\n",
    "                sleep_light_mean.append(np.nan)\n",
    "                sleep_light_std.append(np.nan)\n",
    "                continue\n",
    "    \n",
    "            # sleep length\n",
    "            length = end - start\n",
    "            sleep_lengths.append(length * 5 / 60 / 60)  # hour\n",
    "    \n",
    "            # enmo\n",
    "            enmo_mean = sensor_df[\"enmo\"][start:end].mean()\n",
    "            enmo_std = sensor_df[\"enmo\"][start:end].std()\n",
    "            sleep_enmo_mean.append(enmo_mean)\n",
    "            sleep_enmo_std.append(enmo_std)\n",
    "    \n",
    "            # light\n",
    "            light_mean = sensor_df[\"light\"][start:end].mean()\n",
    "            light_std = sensor_df[\"light\"][start:end].std()\n",
    "            sleep_light_mean.append(light_mean)\n",
    "            sleep_light_std.append(light_std)\n",
    "            \n",
    "        sleep_df = sleep_df.with_columns(\n",
    "            pl.DataFrame(\n",
    "                {\n",
    "                    \"sleep_length\": sleep_lengths,\n",
    "                    \"sleep_enmo_mean\": sleep_enmo_mean,\n",
    "                    \"sleep_enmo_std\": sleep_enmo_std,\n",
    "                    \"sleep_light_mean\": sleep_light_mean,\n",
    "                    \"sleep_light_std\": sleep_light_std,\n",
    "                }\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # leave only high confidence periods\n",
    "        sleep_df = sleep_df.filter((pl.col(\"wakeup_score\") > 1) & (pl.col(\"onset_score\") > 1))\n",
    "        if debug_count < 3:\n",
    "            display(sleep_df.head())\n",
    "        debug_count += 1\n",
    "            \n",
    "    \n",
    "        # agg\n",
    "        feature.update(\n",
    "            {\n",
    "                \"sleep_measurement_count\": sleep_df.shape[0],\n",
    "                \"sleep_length_mean\": sleep_df[\"sleep_length\"].mean(),\n",
    "                \"sleep_length_std\": sleep_df[\"sleep_length\"].std(),\n",
    "                \"sleep_start_mean\": sleep_df[\"onset_time\"].mean(),\n",
    "                \"sleep_start_std\": sleep_df[\"onset_time\"].std(),\n",
    "                \"sleep_end_mean\": sleep_df[\"wakeup_time\"].mean(),\n",
    "                \"sleep_end_std\": sleep_df[\"wakeup_time\"].std(),\n",
    "                \"sleep_enmo_mean_mean\": sleep_df[\"sleep_enmo_mean\"].mean(),\n",
    "                \"sleep_enmo_mean_std\": sleep_df[\"sleep_enmo_mean\"].std(),\n",
    "                \"sleep_enmo_std_mean\": sleep_df[\"sleep_enmo_std\"].mean(),\n",
    "                \"sleep_enmo_std_std\": sleep_df[\"sleep_enmo_std\"].std(),\n",
    "                \"sleep_light_mean_mean\": sleep_df[\"sleep_light_mean\"].mean(),\n",
    "                \"sleep_light_mean_std\": sleep_df[\"sleep_light_mean\"].std(),\n",
    "                \"sleep_light_std_mean\": sleep_df[\"sleep_light_std\"].mean(),\n",
    "                \"sleep_light_std_std\": sleep_df[\"sleep_light_std\"].std(),\n",
    "            }\n",
    "        )\n",
    "        features.append(feature)\n",
    "    output_dir = f\"/kaggle/working/features/{train_or_test}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    feature_df = pl.DataFrame(features).with_columns(pl.col(\"id\").str.slice(3, 8))\n",
    "    feature_df.write_csv(f\"/kaggle/working/features/{train_or_test}/sleep_features.csv\")\n",
    "    print(feature_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "545a95c9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:09:37.563226Z",
     "iopub.status.busy": "2024-12-23T14:09:37.563006Z",
     "iopub.status.idle": "2024-12-23T14:09:44.753731Z",
     "shell.execute_reply": "2024-12-23T14:09:44.752712Z"
    },
    "papermill": {
     "duration": 7.199075,
     "end_time": "2024-12-23T14:09:44.755108",
     "exception": false,
     "start_time": "2024-12-23T14:09:37.556033",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00,  2.97it/s]\n",
      "100%|██████████| 2/2 [00:05<00:00,  2.58s/it]\n",
      "100%|██████████| 2/2 [00:00<00:00, 67.01it/s]\n",
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (5, 13)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>day</th><th>weekday</th><th>onset_time</th><th>wakeup_time</th><th>onset_step</th><th>wakeup_step</th><th>onset_score</th><th>wakeup_score</th><th>sleep_length</th><th>sleep_enmo_mean</th><th>sleep_enmo_std</th><th>sleep_light_mean</th><th>sleep_light_std</th></tr><tr><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>2</td><td>22.091667</td><td>7.041667</td><td>7854</td><td>14298</td><td>5.939998</td><td>6.883044</td><td>8.95</td><td>0.003588</td><td>0.008487</td><td>2.06153</td><td>0.52031</td></tr><tr><td>1</td><td>3</td><td>22.641667</td><td>8.141667</td><td>25530</td><td>32370</td><td>7.395478</td><td>2.857819</td><td>9.5</td><td>0.002427</td><td>0.006132</td><td>2.714605</td><td>1.259364</td></tr><tr><td>2</td><td>4</td><td>21.575</td><td>7.558333</td><td>42042</td><td>49230</td><td>5.715631</td><td>6.638568</td><td>9.983333</td><td>0.003959</td><td>0.007149</td><td>6.441472</td><td>2.73119</td></tr><tr><td>3</td><td>5</td><td>23.141667</td><td>8.241667</td><td>60450</td><td>67002</td><td>8.010484</td><td>3.987538</td><td>9.1</td><td>0.006016</td><td>0.007928</td><td>9.246452</td><td>14.259801</td></tr><tr><td>4</td><td>6</td><td>22.925</td><td>7.008333</td><td>77574</td><td>83394</td><td>8.050978</td><td>2.848315</td><td>8.083333</td><td>0.009862</td><td>0.012524</td><td>0.511077</td><td>0.28813</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (5, 13)\n",
       "┌─────┬─────────┬────────────┬─────────────┬───┬────────────┬────────────┬────────────┬────────────┐\n",
       "│ day ┆ weekday ┆ onset_time ┆ wakeup_time ┆ … ┆ sleep_enmo ┆ sleep_enmo ┆ sleep_ligh ┆ sleep_ligh │\n",
       "│ --- ┆ ---     ┆ ---        ┆ ---         ┆   ┆ _mean      ┆ _std       ┆ t_mean     ┆ t_std      │\n",
       "│ i64 ┆ i64     ┆ f64        ┆ f64         ┆   ┆ ---        ┆ ---        ┆ ---        ┆ ---        │\n",
       "│     ┆         ┆            ┆             ┆   ┆ f64        ┆ f64        ┆ f64        ┆ f64        │\n",
       "╞═════╪═════════╪════════════╪═════════════╪═══╪════════════╪════════════╪════════════╪════════════╡\n",
       "│ 0   ┆ 2       ┆ 22.091667  ┆ 7.041667    ┆ … ┆ 0.003588   ┆ 0.008487   ┆ 2.06153    ┆ 0.52031    │\n",
       "│ 1   ┆ 3       ┆ 22.641667  ┆ 8.141667    ┆ … ┆ 0.002427   ┆ 0.006132   ┆ 2.714605   ┆ 1.259364   │\n",
       "│ 2   ┆ 4       ┆ 21.575     ┆ 7.558333    ┆ … ┆ 0.003959   ┆ 0.007149   ┆ 6.441472   ┆ 2.73119    │\n",
       "│ 3   ┆ 5       ┆ 23.141667  ┆ 8.241667    ┆ … ┆ 0.006016   ┆ 0.007928   ┆ 9.246452   ┆ 14.259801  │\n",
       "│ 4   ┆ 6       ┆ 22.925     ┆ 7.008333    ┆ … ┆ 0.009862   ┆ 0.012524   ┆ 0.511077   ┆ 0.28813    │\n",
       "└─────┴─────────┴────────────┴─────────────┴───┴────────────┴────────────┴────────────┴────────────┘"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 17.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: (2, 18)\n",
      "┌──────────┬────────┬──────┬─────────────┬───┬─────────────┬─────────────┬────────────┬────────────┐\n",
      "│ id       ┆ length ┆ day  ┆ sleep_measu ┆ … ┆ sleep_light ┆ sleep_light ┆ sleep_ligh ┆ sleep_ligh │\n",
      "│ ---      ┆ ---    ┆ ---  ┆ rement_coun ┆   ┆ _mean_mean  ┆ _mean_std   ┆ t_std_mean ┆ t_std_std  │\n",
      "│ str      ┆ i64    ┆ f64  ┆ t           ┆   ┆ ---         ┆ ---         ┆ ---        ┆ ---        │\n",
      "│          ┆        ┆      ┆ ---         ┆   ┆ f64         ┆ f64         ┆ f64        ┆ f64        │\n",
      "│          ┆        ┆      ┆ i64         ┆   ┆             ┆             ┆            ┆            │\n",
      "╞══════════╪════════╪══════╪═════════════╪═══╪═════════════╪═════════════╪════════════╪════════════╡\n",
      "│ 00115b9f ┆ 3610   ┆ 44.0 ┆ null        ┆ … ┆ null        ┆ null        ┆ null       ┆ null       │\n",
      "│ 001f3379 ┆ 33033  ┆ 23.0 ┆ 7           ┆ … ┆ 4.917133    ┆ 4.370878    ┆ 3.281733   ┆ 4.990464   │\n",
      "└──────────┴────────┴──────┴─────────────┴───┴─────────────┴─────────────┴────────────┴────────────┘\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "create_heuristic(paths=glob(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet/id=*/part-0.parquet\"), train_or_test=\"test\")\n",
    "detection(paths=\"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet/id=*/part-0.parquet\", train_or_test=\"test\")\n",
    "feature_engineering(paths=\"/kaggle/working/features/sleep_detection/test/*.parquet\", data_paths=\"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\", train_or_test=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3153216c",
   "metadata": {
    "papermill": {
     "duration": 0.00738,
     "end_time": "2024-12-23T14:09:44.770562",
     "exception": false,
     "start_time": "2024-12-23T14:09:44.763182",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "55ca9efd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:09:44.786234Z",
     "iopub.status.busy": "2024-12-23T14:09:44.786013Z",
     "iopub.status.idle": "2024-12-23T14:09:44.791154Z",
     "shell.execute_reply": "2024-12-23T14:09:44.790574Z"
    },
    "papermill": {
     "duration": 0.014195,
     "end_time": "2024-12-23T14:09:44.792226",
     "exception": false,
     "start_time": "2024-12-23T14:09:44.778031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Handle non-numeric columns\n",
    "def update(df):\n",
    "    global cat_c\n",
    "    for c in cat_c: \n",
    "        df[c] = df[c].fillna('Missing')\n",
    "        df[c] = df[c].astype('category')\n",
    "    return df\n",
    "\n",
    "def create_mapping(column, dataset):\n",
    "    unique_values = dataset[column].unique()\n",
    "    return {value: idx for idx, value in enumerate(unique_values)}\n",
    "\n",
    "\n",
    "# Function to evaluate the predictions and optimize the thresholds\n",
    "def quadratic_weighted_kappa(y_true, y_pred):\n",
    "    return cohen_kappa_score(y_true, y_pred, weights='quadratic')\n",
    "\n",
    "def threshold_Rounder(oof_non_rounded, thresholds):\n",
    "    return np.where(oof_non_rounded < thresholds[0], 0,\n",
    "                    np.where(oof_non_rounded < thresholds[1], 1,\n",
    "                             np.where(oof_non_rounded < thresholds[2], 2, 3)))\n",
    "\n",
    "def evaluate_predictions(thresholds, y_true, oof_non_rounded):\n",
    "    rounded_p = threshold_Rounder(oof_non_rounded, thresholds)\n",
    "    return -quadratic_weighted_kappa(y_true, rounded_p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd46a13",
   "metadata": {
    "papermill": {
     "duration": 0.007132,
     "end_time": "2024-12-23T14:09:44.806862",
     "exception": false,
     "start_time": "2024-12-23T14:09:44.799730",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Function to train the model with processed time series data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "11a895e4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:09:44.822285Z",
     "iopub.status.busy": "2024-12-23T14:09:44.822059Z",
     "iopub.status.idle": "2024-12-23T14:09:44.829836Z",
     "shell.execute_reply": "2024-12-23T14:09:44.829027Z"
    },
    "papermill": {
     "duration": 0.016957,
     "end_time": "2024-12-23T14:09:44.831153",
     "exception": false,
     "start_time": "2024-12-23T14:09:44.814196",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def TrainML(model_class, X, y, test_data):\n",
    "    SKF = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    train_S = []\n",
    "    test_S = []\n",
    "    \n",
    "    oof_non_rounded = np.zeros(len(y), dtype=float) \n",
    "    oof_rounded = np.zeros(len(y), dtype=int) \n",
    "    test_preds = np.zeros((len(test_data), n_splits))\n",
    "\n",
    "    for fold, (train_idx, test_idx) in enumerate(tqdm(SKF.split(X, y), desc=\"Training Folds\", total=n_splits)):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[test_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[test_idx]\n",
    "        model = clone(model_class)\n",
    "        model.fit(X_train, y_train)\n",
    "\n",
    "        y_train_pred = model.predict(X_train)\n",
    "        y_val_pred = model.predict(X_val)\n",
    "\n",
    "        oof_non_rounded[test_idx] = y_val_pred\n",
    "        y_val_pred_rounded = y_val_pred.round(0).astype(int)\n",
    "        oof_rounded[test_idx] = y_val_pred_rounded\n",
    "\n",
    "        train_kappa = quadratic_weighted_kappa(y_train, y_train_pred.round(0).astype(int))\n",
    "        val_kappa = quadratic_weighted_kappa(y_val, y_val_pred_rounded)\n",
    "\n",
    "        train_S.append(train_kappa)\n",
    "        test_S.append(val_kappa)\n",
    "        \n",
    "        test_preds[:, fold] = model.predict(test_data)\n",
    "        \n",
    "        print(f\"Fold {fold+1} - Train QWK: {train_kappa:.4f}, Validation QWK: {val_kappa:.4f}\")\n",
    "        clear_output(wait=True)\n",
    "    print(f\"Mean Train QWK --> {np.mean(train_S):.4f}\")\n",
    "    print(f\"Mean Validation QWK ---> {np.mean(test_S):.4f}\")\n",
    "\n",
    "    KappaOPtimizer = minimize(evaluate_predictions,\n",
    "                              x0=[0.5, 1.5, 2.5], args=(y, oof_non_rounded), \n",
    "                              method='Nelder-Mead')\n",
    "    assert KappaOPtimizer.success, \"Optimization did not converge.\"\n",
    "    print('OPTIMIZED THRESHOLDS', KappaOPtimizer.x)\n",
    "    oof_tuned = threshold_Rounder(oof_non_rounded, KappaOPtimizer.x)\n",
    "    tKappa = quadratic_weighted_kappa(y, oof_tuned)\n",
    "\n",
    "    print(f\"----> || Optimized QWK SCORE :: {Fore.CYAN}{Style.BRIGHT} {tKappa:.3f}{Style.RESET_ALL}\")\n",
    "\n",
    "    tpm = test_preds.mean(axis=1)\n",
    "    tpTuned = threshold_Rounder(tpm, KappaOPtimizer.x)\n",
    "    \n",
    "    submission = pd.DataFrame({\n",
    "        'id': sample['id'],\n",
    "        'sii': tpTuned\n",
    "    })\n",
    "    optimized_thresholds = KappaOPtimizer.x\n",
    "    return submission, oof_tuned, oof_non_rounded, y, optimized_thresholds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be36cb22",
   "metadata": {
    "papermill": {
     "duration": 0.007148,
     "end_time": "2024-12-23T14:09:44.845814",
     "exception": false,
     "start_time": "2024-12-23T14:09:44.838666",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Utils functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "97eb855a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:09:44.861194Z",
     "iopub.status.busy": "2024-12-23T14:09:44.860988Z",
     "iopub.status.idle": "2024-12-23T14:09:44.865918Z",
     "shell.execute_reply": "2024-12-23T14:09:44.865134Z"
    },
    "papermill": {
     "duration": 0.014034,
     "end_time": "2024-12-23T14:09:44.867273",
     "exception": false,
     "start_time": "2024-12-23T14:09:44.853239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_file(filename, dirname):\n",
    "    df = pd.read_parquet(os.path.join(dirname, filename, 'part-0.parquet'))\n",
    "    df.drop('step', axis=1, inplace=True)\n",
    "    return df.describe().values.reshape(-1), filename.split('=')[1]\n",
    "\n",
    "def load_time_series(dirname) -> pd.DataFrame:\n",
    "    ids = os.listdir(dirname)\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        results = list(tqdm(executor.map(lambda fname: process_file(fname, dirname), ids), total=len(ids)))\n",
    "    stats, indexes = zip(*results)\n",
    "    df = pd.DataFrame(stats, columns=[f\"stat_{i}\" for i in range(len(stats[0]))])\n",
    "    df['id'] = indexes\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22bd8261",
   "metadata": {
    "papermill": {
     "duration": 0.007379,
     "end_time": "2024-12-23T14:09:44.882141",
     "exception": false,
     "start_time": "2024-12-23T14:09:44.874762",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Define features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dfbbdb3",
   "metadata": {
    "papermill": {
     "duration": 0.007136,
     "end_time": "2024-12-23T14:09:44.896570",
     "exception": false,
     "start_time": "2024-12-23T14:09:44.889434",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Normal features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5db1002d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:09:44.912648Z",
     "iopub.status.busy": "2024-12-23T14:09:44.912371Z",
     "iopub.status.idle": "2024-12-23T14:09:44.969072Z",
     "shell.execute_reply": "2024-12-23T14:09:44.968419Z"
    },
    "papermill": {
     "duration": 0.06614,
     "end_time": "2024-12-23T14:09:44.970313",
     "exception": false,
     "start_time": "2024-12-23T14:09:44.904173",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/test.csv')\n",
    "sample = pd.read_csv('/kaggle/input/child-mind-institute-problematic-internet-use/sample_submission.csv')\n",
    "\n",
    "total_features = list(test.columns)\n",
    "total_features.remove('id')\n",
    "\n",
    "cat_c = ['Basic_Demos-Enroll_Season', 'CGAS-Season', 'Physical-Season', \n",
    "          'Fitness_Endurance-Season', 'FGC-Season', 'BIA-Season', \n",
    "          'PAQ_A-Season', 'PAQ_C-Season', 'SDS-Season', 'PreInt_EduHx-Season']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "589c1b9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:09:44.986776Z",
     "iopub.status.busy": "2024-12-23T14:09:44.986549Z",
     "iopub.status.idle": "2024-12-23T14:09:44.989305Z",
     "shell.execute_reply": "2024-12-23T14:09:44.988722Z"
    },
    "papermill": {
     "duration": 0.012361,
     "end_time": "2024-12-23T14:09:44.990597",
     "exception": false,
     "start_time": "2024-12-23T14:09:44.978236",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# noseason_features = ['Basic_Demos-Age', 'Basic_Demos-Sex',\n",
    "#                 'CGAS-CGAS_Score', 'Physical-BMI',\n",
    "#                 'Physical-Height', 'Physical-Weight', 'Physical-Waist_Circumference',\n",
    "#                 'Physical-Diastolic_BP', 'Physical-HeartRate', 'Physical-Systolic_BP',\n",
    "#                 'Fitness_Endurance-Max_Stage',\n",
    "#                 'Fitness_Endurance-Time_Mins', 'Fitness_Endurance-Time_Sec',\n",
    "#                 'FGC-FGC_CU', 'FGC-FGC_CU_Zone', 'FGC-FGC_GSND',\n",
    "#                 'FGC-FGC_GSND_Zone', 'FGC-FGC_GSD', 'FGC-FGC_GSD_Zone', 'FGC-FGC_PU',\n",
    "#                 'FGC-FGC_PU_Zone', 'FGC-FGC_SRL', 'FGC-FGC_SRL_Zone', 'FGC-FGC_SRR',\n",
    "#                 'FGC-FGC_SRR_Zone', 'FGC-FGC_TL', 'FGC-FGC_TL_Zone',\n",
    "#                 'BIA-BIA_Activity_Level_num', 'BIA-BIA_BMC', 'BIA-BIA_BMI',\n",
    "#                 'BIA-BIA_BMR', 'BIA-BIA_DEE', 'BIA-BIA_ECW', 'BIA-BIA_FFM',\n",
    "#                 'BIA-BIA_FFMI', 'BIA-BIA_FMI', 'BIA-BIA_Fat', 'BIA-BIA_Frame_num',\n",
    "#                 'BIA-BIA_ICW', 'BIA-BIA_LDM', 'BIA-BIA_LST', 'BIA-BIA_SMM',\n",
    "#                 'BIA-BIA_TBW', 'PAQ_A-PAQ_A_Total',\n",
    "#                 'PAQ_C-PAQ_C_Total', 'SDS-SDS_Total_Raw',\n",
    "#                 'SDS-SDS_Total_T',\n",
    "#                 'PreInt_EduHx-computerinternet_hoursday', 'BMI_Age','Internet_Hours_Age','BMI_Internet_Hours',\n",
    "#                 'BFP_BMI', 'FFMI_BFP', 'FMI_BFP', 'LST_TBW', 'BFP_BMR', 'BFP_DEE', 'BMR_Weight', 'DEE_Weight',\n",
    "#                 'SMM_Height', 'Muscle_to_Fat', 'Hydration_Status', 'ICW_TBW','BMI_PHR']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "940d0b4f",
   "metadata": {
    "papermill": {
     "duration": 0.007349,
     "end_time": "2024-12-23T14:09:45.005985",
     "exception": false,
     "start_time": "2024-12-23T14:09:44.998636",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Loading timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b0ada6e5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:09:45.021486Z",
     "iopub.status.busy": "2024-12-23T14:09:45.021258Z",
     "iopub.status.idle": "2024-12-23T14:10:52.881885Z",
     "shell.execute_reply": "2024-12-23T14:10:52.880870Z"
    },
    "papermill": {
     "duration": 67.869821,
     "end_time": "2024-12-23T14:10:52.883222",
     "exception": false,
     "start_time": "2024-12-23T14:09:45.013401",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 996/996 [01:07<00:00, 14.72it/s]\n",
      "100%|██████████| 2/2 [00:00<00:00, 14.16it/s]\n"
     ]
    }
   ],
   "source": [
    "train_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_train.parquet\")\n",
    "test_ts = load_time_series(\"/kaggle/input/child-mind-institute-problematic-internet-use/series_test.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cce23626",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:10:52.928047Z",
     "iopub.status.busy": "2024-12-23T14:10:52.927794Z",
     "iopub.status.idle": "2024-12-23T14:11:01.569618Z",
     "shell.execute_reply": "2024-12-23T14:11:01.568527Z"
    },
    "papermill": {
     "duration": 8.665376,
     "end_time": "2024-12-23T14:11:01.571145",
     "exception": false,
     "start_time": "2024-12-23T14:10:52.905769",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100], Loss: 1.4650]\n",
      "Epoch [100/100], Loss: 1.3985]\n"
     ]
    }
   ],
   "source": [
    "df_train = train_ts.drop('id', axis=1)\n",
    "df_test = test_ts.drop('id', axis=1)\n",
    "autoencoder, scaler = perform_autoencoder(df_train, encoding_dim=60, epochs=100, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8f16d72a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:11:01.616375Z",
     "iopub.status.busy": "2024-12-23T14:11:01.616111Z",
     "iopub.status.idle": "2024-12-23T14:11:01.627880Z",
     "shell.execute_reply": "2024-12-23T14:11:01.627019Z"
    },
    "papermill": {
     "duration": 0.034475,
     "end_time": "2024-12-23T14:11:01.629238",
     "exception": false,
     "start_time": "2024-12-23T14:11:01.594763",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ts_encoded = encode_data(autoencoder, scaler, df_train)\n",
    "test_ts_encoded = encode_data(autoencoder, scaler, df_test)\n",
    "test_ts_encoded.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ce3098de",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:11:01.672101Z",
     "iopub.status.busy": "2024-12-23T14:11:01.671824Z",
     "iopub.status.idle": "2024-12-23T14:11:01.676091Z",
     "shell.execute_reply": "2024-12-23T14:11:01.675407Z"
    },
    "papermill": {
     "duration": 0.026859,
     "end_time": "2024-12-23T14:11:01.677204",
     "exception": false,
     "start_time": "2024-12-23T14:11:01.650345",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ts_encoded[\"id\"]=train_ts[\"id\"]\n",
    "test_ts_encoded['id']=test_ts[\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5970205",
   "metadata": {
    "papermill": {
     "duration": 0.020338,
     "end_time": "2024-12-23T14:11:01.718249",
     "exception": false,
     "start_time": "2024-12-23T14:11:01.697911",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Features timeseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3017f32d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:11:01.760606Z",
     "iopub.status.busy": "2024-12-23T14:11:01.760314Z",
     "iopub.status.idle": "2024-12-23T14:11:01.763907Z",
     "shell.execute_reply": "2024-12-23T14:11:01.763260Z"
    },
    "papermill": {
     "duration": 0.025873,
     "end_time": "2024-12-23T14:11:01.764993",
     "exception": false,
     "start_time": "2024-12-23T14:11:01.739120",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "time_series_cols = train_ts.columns.tolist()\n",
    "time_series_cols.remove(\"id\")\n",
    "time_encoded_cols = train_ts_encoded.columns.tolist()\n",
    "time_encoded_cols.remove(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecc383d6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:11:01.807045Z",
     "iopub.status.busy": "2024-12-23T14:11:01.806834Z",
     "iopub.status.idle": "2024-12-23T14:11:01.821253Z",
     "shell.execute_reply": "2024-12-23T14:11:01.820699Z"
    },
    "papermill": {
     "duration": 0.036776,
     "end_time": "2024-12-23T14:11:01.822426",
     "exception": false,
     "start_time": "2024-12-23T14:11:01.785650",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sleep = pd.read_csv(\"/kaggle/input/train-sleep/sleep_features.csv\")\n",
    "test_sleep = pd.read_csv(\"/kaggle/working/features/test/sleep_features.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7419a0b3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:11:01.864061Z",
     "iopub.status.busy": "2024-12-23T14:11:01.863850Z",
     "iopub.status.idle": "2024-12-23T14:11:01.866904Z",
     "shell.execute_reply": "2024-12-23T14:11:01.866285Z"
    },
    "papermill": {
     "duration": 0.025169,
     "end_time": "2024-12-23T14:11:01.868004",
     "exception": false,
     "start_time": "2024-12-23T14:11:01.842835",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "sleep_cols = train_sleep.columns.tolist()\n",
    "sleep_cols.remove(\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40a2c617",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:11:01.909560Z",
     "iopub.status.busy": "2024-12-23T14:11:01.909323Z",
     "iopub.status.idle": "2024-12-23T14:11:02.077254Z",
     "shell.execute_reply": "2024-12-23T14:11:02.076010Z"
    },
    "papermill": {
     "duration": 0.190709,
     "end_time": "2024-12-23T14:11:02.079017",
     "exception": false,
     "start_time": "2024-12-23T14:11:01.888308",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rm -rf /kaggle/working/features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "539fe078",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:11:02.122066Z",
     "iopub.status.busy": "2024-12-23T14:11:02.121756Z",
     "iopub.status.idle": "2024-12-23T14:11:02.281703Z",
     "shell.execute_reply": "2024-12-23T14:11:02.280693Z"
    },
    "papermill": {
     "duration": 0.183006,
     "end_time": "2024-12-23T14:11:02.283235",
     "exception": false,
     "start_time": "2024-12-23T14:11:02.100229",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rm -rf /kaggle/working/heuristic_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52dc65d",
   "metadata": {
    "papermill": {
     "duration": 0.020585,
     "end_time": "2024-12-23T14:11:02.325152",
     "exception": false,
     "start_time": "2024-12-23T14:11:02.304567",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Final features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3f20842e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:11:02.367974Z",
     "iopub.status.busy": "2024-12-23T14:11:02.367683Z",
     "iopub.status.idle": "2024-12-23T14:11:02.398941Z",
     "shell.execute_reply": "2024-12-23T14:11:02.398104Z"
    },
    "papermill": {
     "duration": 0.054608,
     "end_time": "2024-12-23T14:11:02.400340",
     "exception": false,
     "start_time": "2024-12-23T14:11:02.345732",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_sub2 = pd.merge(train, train_sleep, how=\"left\", on='id')\n",
    "test_sub2 = pd.merge(test, test_sleep, how=\"left\", on='id')\n",
    "train_season_cols = [col for col in train_sub2.columns if 'Season' in col]\n",
    "test_season_cols = [col for col in test_sub2.columns if 'Season' in col]\n",
    "\n",
    "train_sub2 = train_sub2.drop(train_season_cols, axis=1) \n",
    "test_sub2 = test_sub2.drop(test_season_cols, axis=1) \n",
    "\n",
    "train_sub2 = train_sub2.drop('id', axis=1)\n",
    "test_sub2  = test_sub2.drop('id', axis=1)  \n",
    "train_sub2 = train_sub2.dropna(subset='sii')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2de78b",
   "metadata": {
    "papermill": {
     "duration": 0.021717,
     "end_time": "2024-12-23T14:11:02.443176",
     "exception": false,
     "start_time": "2024-12-23T14:11:02.421459",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bff73e1",
   "metadata": {
    "papermill": {
     "duration": 0.020758,
     "end_time": "2024-12-23T14:11:02.484482",
     "exception": false,
     "start_time": "2024-12-23T14:11:02.463724",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8faea49a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:11:02.526584Z",
     "iopub.status.busy": "2024-12-23T14:11:02.526257Z",
     "iopub.status.idle": "2024-12-23T14:11:02.537891Z",
     "shell.execute_reply": "2024-12-23T14:11:02.537229Z"
    },
    "papermill": {
     "duration": 0.034247,
     "end_time": "2024-12-23T14:11:02.539160",
     "exception": false,
     "start_time": "2024-12-23T14:11:02.504913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SVR_Best_Params = {\n",
    "    'C': 0.1,\n",
    "    'epsilon': 0.1,\n",
    "    'kernel': 'rbf',\n",
    "    'gamma': 'scale',\n",
    "}\n",
    "\n",
    "CatBoost_Best_Params = {\n",
    "    'learning_rate': 0.0021172579310639343,\n",
    "    'depth': 6,\n",
    "    'iterations': 130,\n",
    "    'random_seed': SEED,\n",
    "    'verbose': 0,\n",
    "    'l2_leaf_reg': 0.32557701990001503,\n",
    "    'task_type': 'GPU',  \n",
    "    'devices': '0'\n",
    "}\n",
    "\n",
    "XGB_Best_Params = {\n",
    "    'n_estimators': 700,\n",
    "    'max_depth': 4,\n",
    "    'learning_rate': 0.03325152156380898,\n",
    "    'subsample': 0.25295047248406266,\n",
    "    'colsample_bytree': 0.9760859719849787,\n",
    "    'gamma': 0.20085951790463402,\n",
    "    'min_child_weight': 11,\n",
    "    'eval_metric': 'rmse',\n",
    "    'objective': 'reg:squarederror',\n",
    "    'tree_method': 'gpu_hist',\n",
    "    'predictor': 'gpu_predictor',\n",
    "    'gpu_id': 0\n",
    "}\n",
    "\n",
    "LightGBM_Best_Params = {\n",
    "    'max_depth': 3,\n",
    "    'min_data_in_leaf': 40,\n",
    "    'num_leaves': 190,\n",
    "    'learning_rate': 0.05107368421432176,\n",
    "    'feature_fraction': 0.9918350138636185,\n",
    "    'bagging_fraction': 0.9331400899763774,\n",
    "    'bagging_freq': 1,\n",
    "    'lambda_l1': 9.49641646280519,\n",
    "    'lambda_l2': 2.446305429623661,\n",
    "    'min_gain_to_split': 0.05262124930522051,\n",
    "    'device_type': 'gpu',\n",
    "    'gpu_device_id': 0,\n",
    "    'verbosity': -1\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "catboost_model = CatBoostRegressor(**CatBoost_Best_Params)\n",
    "xgb_model = XGBRegressor(**XGB_Best_Params)\n",
    "lightgbm_model = LGBMRegressor(**LightGBM_Best_Params)\n",
    "svr_model = SVR(**SVR_Best_Params)\n",
    "\n",
    "final_voting_model = VotingRegressor(estimators=[\n",
    "    ('lightgbm', lightgbm_model),\n",
    "    ('xgboost', xgb_model),\n",
    "    ('catboost', catboost_model),\n",
    "], weights=[4.0, 4.0, 4.0])\n",
    "\n",
    "# features_sub2 = noseason_features + sleep_cols\n",
    "feature_cols = test_sub2.columns\n",
    "y = train_sub2['sii']\n",
    "X = train_sub2[feature_cols]\n",
    "test_sub2 = test_sub2[feature_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2cf4f13a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:11:02.580932Z",
     "iopub.status.busy": "2024-12-23T14:11:02.580718Z",
     "iopub.status.idle": "2024-12-23T14:11:17.230140Z",
     "shell.execute_reply": "2024-12-23T14:11:17.229302Z"
    },
    "papermill": {
     "duration": 14.671986,
     "end_time": "2024-12-23T14:11:17.231588",
     "exception": false,
     "start_time": "2024-12-23T14:11:02.559602",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Folds: 100%|██████████| 5/5 [00:14<00:00,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Train QWK --> 0.5417\n",
      "Mean Validation QWK ---> 0.3581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OPTIMIZED THRESHOLDS [0.57729174 0.85612963 2.68808628]\n",
      "----> || Optimized QWK SCORE :: \u001b[36m\u001b[1m 0.466\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "submission2, _, _, _, _= TrainML(final_voting_model, X, y, test_sub2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1850755",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:11:17.282986Z",
     "iopub.status.busy": "2024-12-23T14:11:17.282690Z",
     "iopub.status.idle": "2024-12-23T14:11:17.290986Z",
     "shell.execute_reply": "2024-12-23T14:11:17.290084Z"
    },
    "papermill": {
     "duration": 0.031527,
     "end_time": "2024-12-23T14:11:17.292439",
     "exception": false,
     "start_time": "2024-12-23T14:11:17.260912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to 'submission.csv'\n"
     ]
    }
   ],
   "source": [
    "final_submission = submission2\n",
    "final_submission.to_csv('submission.csv', index=False)\n",
    "\n",
    "print(\"Submission saved to 'submission.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "faa4c43b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-12-23T14:11:17.340987Z",
     "iopub.status.busy": "2024-12-23T14:11:17.340702Z",
     "iopub.status.idle": "2024-12-23T14:11:17.353090Z",
     "shell.execute_reply": "2024-12-23T14:11:17.352368Z"
    },
    "papermill": {
     "duration": 0.035251,
     "end_time": "2024-12-23T14:11:17.354323",
     "exception": false,
     "start_time": "2024-12-23T14:11:17.319072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sii</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00008ff9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000fd460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00105258</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>00115b9f</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0016bb22</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>001f3379</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0038ba98</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0068a485</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0069fbed</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0083e397</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0087dd65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>00abe655</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>00ae59c9</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>00af6387</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>00bd4359</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>00c0cd71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>00d56d4b</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>00d9913d</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>00e6167c</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>00ebc35d</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          id  sii\n",
       "0   00008ff9    1\n",
       "1   000fd460    0\n",
       "2   00105258    0\n",
       "3   00115b9f    0\n",
       "4   0016bb22    1\n",
       "5   001f3379    1\n",
       "6   0038ba98    0\n",
       "7   0068a485    0\n",
       "8   0069fbed    1\n",
       "9   0083e397    1\n",
       "10  0087dd65    0\n",
       "11  00abe655    0\n",
       "12  00ae59c9    1\n",
       "13  00af6387    1\n",
       "14  00bd4359    1\n",
       "15  00c0cd71    1\n",
       "16  00d56d4b    0\n",
       "17  00d9913d    0\n",
       "18  00e6167c    0\n",
       "19  00ebc35d    1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258a6406",
   "metadata": {
    "papermill": {
     "duration": 0.021163,
     "end_time": "2024-12-23T14:11:17.396885",
     "exception": false,
     "start_time": "2024-12-23T14:11:17.375722",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 9643020,
     "sourceId": 81933,
     "sourceType": "competition"
    },
    {
     "datasetId": 921302,
     "sourceId": 7453542,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5742470,
     "sourceId": 9448132,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5742473,
     "sourceId": 9448136,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6324642,
     "sourceId": 10229352,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6327724,
     "sourceId": 10233697,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 6360724,
     "sourceId": 10279281,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30823,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 124.83982,
   "end_time": "2024-12-23T14:11:20.746776",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-12-23T14:09:15.906956",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
